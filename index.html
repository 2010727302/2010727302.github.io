<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/blue/pace-theme-minimal.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"2010727302.github.io","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.18.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"slideUpIn"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.json","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="Yuhan Wang&#39;s Blog">
<meta property="og:type" content="website">
<meta property="og:title" content="一个田螺突然就">
<meta property="og:url" content="https://2010727302.github.io/index.html">
<meta property="og:site_name" content="一个田螺突然就">
<meta property="og:description" content="Yuhan Wang&#39;s Blog">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Yuhan Wang">
<meta property="article:tag" content="C++,算法">
<meta name="twitter:card" content="&lt;twitter:card&gt;">
<meta name="twitter:image" content="https://2010727302.github.io/%3Ctwitter:image%3E">
<meta name="twitter:creator" content="@&lt;twitter:creator&gt;">
<meta name="twitter:site" content="<twitter:site>">
<link rel="publisher" href="%3Cg+:profile_link%3E">
<meta property="fb:admins" content="&lt;fb:admin_id&gt;">
<meta property="fb:app_id" content="&lt;fb:app_id&gt;">


<link rel="canonical" href="https://2010727302.github.io/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>一个田螺突然就</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">一个田螺突然就</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">转山转水转不出自我</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-schedule"><a href="/schedule/" rel="section"><i class="fa fa-calendar fa-fw"></i>日程表</a></li><li class="menu-item menu-item-sitemap"><a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>站点地图</a></li><li class="menu-item menu-item-commonweal"><a href="/404/" rel="section"><i class="fa fa-heartbeat fa-fw"></i>公益 404</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">
    
    <div class="sidebar-inner sidebar-overview-active">
      
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>
      <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Yuhan Wang"
      src="/images/avatar4.jpg">
  <p class="site-author-name" itemprop="name">Yuhan Wang</p>
  <div class="site-description" itemprop="description">Yuhan Wang's Blog</div>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/2010727302" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;2010727302" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:yigetianluoturanjiu@gmail.com" title="E-Mail → mailto:yigetianluoturanjiu@gmail.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>

      </div>
      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
          <div id="toc-div">
        </div>
        <!--/noindex-->

        
      </div>
    </div>
    
    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://2010727302.github.io/2025/12/21/LCRON/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar4.jpg">
      <meta itemprop="name" content="Yuhan Wang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="一个田螺突然就">
      <meta itemprop="description" content="Yuhan Wang's Blog">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 一个田螺突然就">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/12/21/LCRON/" class="post-title-link" itemprop="url">LCRON</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-12-21 19:06:19" itemprop="dateCreated datePublished" datetime="2025-12-21T19:06:19+08:00">2025-12-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-12-22 18:45:08" itemprop="dateModified" datetime="2025-12-22T18:45:08+08:00">2025-12-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/research/" itemprop="url" rel="index"><span itemprop="name">research</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/research/prerank/" itemprop="url" rel="index"><span itemprop="name">prerank</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p><a target="_blank" rel="noopener" href="https://blog.csdn.net/kuaishoutech/article/details/149599655">参考</a><br><img src="/2025/12/21/LCRON/image.png"><br>$\prod_{i:\pi_i&#x3D;1}$ 是数学中的连乘（Product）符号加上一个筛选条件。1. $\prod$ (大写的 Pi)：代表连乘（即把后面所有的项乘起来），就像 $\sum$ 代表连加一样。下标 $i$：表示索引变量。冒号 $:$：表示“满足……条件”（such that）。$\pi_i &#x3D; 1$：这是筛选条件。</p>
<h1 id="两阶段建模解析"><a href="#两阶段建模解析" class="headerlink" title="两阶段建模解析"></a>两阶段建模解析</h1><ul>
<li>**总商品库 ($N$)**：只有 4 个商品 ${A, B, C, D}$。</li>
<li>**真实情况 ($\mathbf{y}$)**：用户只喜欢 A 和 C。</li>
<li><strong>阶段 1 任务</strong>：从中选 2 个 ($q_1&#x3D;2$) 给阶段 2。</li>
<li><strong>阶段 2 任务</strong>：给这 2 个打分，算出最终概率。</li>
</ul>
<hr>
<h2 id="公式一：交叉熵损失-CE-Loss"><a href="#公式一：交叉熵损失-CE-Loss" class="headerlink" title="公式一：交叉熵损失 (CE Loss)"></a>公式一：交叉熵损失 (CE Loss)</h2><p>$$CE(P_{CS}^{q_2}, \mathbf{y}) &#x3D; -\sum_i (y_i \ln((P_{CS}^{q_2})<em>i) + (1-y_i)\ln(1-(P</em>{CS}^{q_2})_i))$$</p>
<p>这个公式是最终的裁判，用来衡量模型预测得准不准。</p>
<ul>
<li>**$P_{CS}^{q_2}$ (Prediction)**：系统最终预测的生存概率向量。<ul>
<li><strong>例子</strong>：假设模型算出来 A、B、C、D 最终被选中的概率是 $[0.8, 0.2, 0.6, 0.1]$。</li>
</ul>
</li>
<li>**$\mathbf{y}$ (Ground Truth)**：真实标签向量（二值向量）。<ul>
<li><strong>含义</strong>：用户实际点击了哪些。</li>
<li><strong>例子</strong>：用户喜欢 A 和 C，不喜欢 B 和 D。所以 $\mathbf{y} &#x3D; [1, 0, 1, 0]$。</li>
</ul>
</li>
<li>**$i$**：商品索引。含义：遍历每一个商品 (A, B, C, D)。</li>
<li>**$\sum_i$**：求和。含义：把所有商品的判断误差加起来，变成一个总的 Loss 值。</li>
<li>**$\ln$**：自然对数。</li>
</ul>
<p><strong>计算逻辑</strong>：</p>
<ul>
<li>对于商品 A ($y&#x3D;1$)：我们要最大化 $\ln(0.8)$。</li>
<li>对于商品 B ($y&#x3D;0$)：我们要最大化 $\ln(1-0.2)$。</li>
<li>如果预测反了（比如 A 预测成 0.1），$\ln(0.1)$ 是个很大的负数，取负号后 Loss 就会变得超级大。</li>
</ul>
<hr>
<h2 id="公式二：采样概率-P-pi"><a href="#公式二：采样概率-P-pi" class="headerlink" title="公式二：采样概率 ($P_\pi$)"></a>公式二：采样概率 ($P_\pi$)</h2><p>$$P_\pi &#x3D; \frac{\prod_{i:\pi_i&#x3D;1} (P_{\mathcal{M}<em>1}^{q_1})<em>i}{\sum</em>{S \subseteq [N], |S|&#x3D;T} \prod</em>{j \in S} (P_{\mathcal{M}_1}^{q_1})_j}$$</p>
<p>这个公式描述的是阶段 1 (粗排模型) 的行为：它选出某一种特定组合的概率是多少？</p>
<ul>
<li>**$P_{\mathcal{M}_1}^{q_1}$**：粗排模型的打分向量。<ul>
<li><strong>例子</strong>：模型 1 觉得四个商品的分数是 $[0.9, 0.1, 0.8, 0.2]$ (A, B, C, D)。</li>
</ul>
</li>
<li>**$\pi$**：一种具体的采样结果（Mask）。<ul>
<li><strong>含义</strong>：比如“选中 A 和 C”这种组合，表示为 $[1, 0, 1, 0]$。</li>
</ul>
</li>
<li>**$\prod_{i:\pi_i&#x3D;1}$**：只乘选中的项（分子部分）。<ul>
<li><strong>例子</strong>：对于组合 ${A, C}$，分子 &#x3D; $0.9 \times 0.8 &#x3D; 0.72$。</li>
</ul>
</li>
<li>**$S \subseteq [N], |S|&#x3D;T$**：分母里的求和条件。<ul>
<li><strong>含义</strong>：遍历所有可能的长度为 $T$ ($T&#x3D;q_1$) 的子集。</li>
<li><strong>例子</strong>：我们要从 4 个里选 2 个，所有可能的组合有 6 种：(AB, AC, AD, BC, BD, CD)。</li>
</ul>
</li>
<li>**分母整体 $\sum \prod$**：归一化系数。<ul>
<li><strong>含义</strong>：算出所有 6 种组合的分数乘积之和，作为分母，确保所有概率加起来等于 1。</li>
</ul>
</li>
<li><strong>计算</strong>：<ul>
<li>AB: $0.9 \times 0.1 &#x3D; 0.09$</li>
<li>AC: $0.9 \times 0.8 &#x3D; 0.72$</li>
<li>…以此类推算出总和。</li>
</ul>
</li>
<li><strong>结果</strong>：$P_\pi(\text{选AC}) &#x3D; \frac{0.72}{\text{总和}}$。这表示“选中 A 和 C 这一对”的概率。</li>
</ul>
<hr>
<h2 id="公式三：最终生存概率-P-CS-q-2"><a href="#公式三：最终生存概率-P-CS-q-2" class="headerlink" title="公式三：最终生存概率 ($P_{CS}^{q_2}$)"></a>公式三：最终生存概率 ($P_{CS}^{q_2}$)</h2><p>$$P_{CS}^{q_2} &#x3D; \mathbb{E}<em>{\pi \sim P_\pi} \frac{(P</em>{\mathcal{M}<em>2}^{q_2} \odot \pi)}{\langle \pi, P</em>{\mathcal{M}<em>2}^{q_2} \rangle &#x2F; \langle \mathbf{1}, P</em>{\mathcal{M}_2}^{q_2} \rangle}$$</p>
<p>这个公式把两个阶段结合起来，计算在考虑了粗排筛选风险的情况下，精排模型给出的期望分数。</p>
<ul>
<li>**$\mathbb{E}_{\pi \sim P_\pi}$**：数学期望。<ul>
<li><strong>含义</strong>：因为粗排是个概率过程（可能选 AC，也可能选 AD），我们需要把所有情况按照它们发生的概率 ($P_\pi$) 加权平均。</li>
</ul>
</li>
<li>**$P_{\mathcal{M}_2}^{q_2}$**：精排模型的打分向量。<ul>
<li><strong>例子</strong>：模型 2 比较准，分数是 $[0.95, 0.05, 0.95, 0.05]$ (A, B, C, D)。</li>
</ul>
</li>
<li>**$\odot \pi$**：掩码操作（Hadamard 积）。<ul>
<li><strong>含义</strong>：如果粗排没选中（$\pi$ 对应位置是 0），精排分再高也没用，直接置零。</li>
<li><strong>例子</strong>：如果 $\pi$ 选了 AC ($[1,0,1,0]$)，那么 B 和 D 的分变成 0。向量变为 $[0.95, 0, 0.95, 0]$。</li>
</ul>
</li>
<li>**$\langle \pi, P_{\mathcal{M}_2}^{q_2} \rangle$**：被选中的物品的总分（点积）。<ul>
<li><strong>例子</strong>：$0.95 \text{(A)} + 0.95 \text{(C)} &#x3D; 1.9$。</li>
</ul>
</li>
<li>**$\langle \mathbf{1}, P_{\mathcal{M}_2}^{q_2} \rangle$**：所有物品的总分。<ul>
<li><strong>例子</strong>：$0.95+0.05+0.95+0.05 &#x3D; 2.0$。</li>
</ul>
</li>
<li><strong>分母里的除法</strong>：权重归一化。<ul>
<li><strong>含义</strong>：$1.9 &#x2F; 2.0 &#x3D; 0.95$。这个系数代表“当前选中的这一组，占了总分数的 95%”。</li>
</ul>
</li>
</ul>
<p><strong>整体逻辑</strong>：<br>拿“被掩码后的分数”除以“该组合的权重占比”。如果粗排经常把高分物品漏掉（$\pi$ 经常是 $[0,1,0,1]$），那么期望值里的有效分数就会很低，最终 $P_{CS}$ 就会很小。</p>
<p>$P_{CS}^{q_2} &#x3D; \sum_{\text{所有可能的 } \pi} \left( P_\pi \cdot f(\pi) \right)$</p>
<p>假设只有 3 个商品，粗排选 2 个：<br>组合与概率：</p>
<ul>
<li>选 ${A, B}$ 的概率 $P_{\pi_1} &#x3D; 0.8$</li>
<li>选 ${B, C}$ 的概率 $P_{\pi_2} &#x3D; 0.2$（假设选 ${A, C}$ 概率为 0）<br>算得分：</li>
<li>如果选了 ${A, B}$，算出的归一化得分向量是 $[0.9, 0.1, 0]$。</li>
<li>如果选了 ${B, C}$，算出的归一化得分向量是 $[0, 0.5, 0.5]$。<br>算期望：<br>$P_{CS} &#x3D; 0.8 \times [0.9, 0.1, 0] + 0.2 \times [0, 0.5, 0.5]$<br>$P_{CS} &#x3D; [0.72, 0.08, 0] + [0, 0.1, 0.1] &#x3D; [0.72, 0.18, 0.1]$</li>
</ul>
<hr>
<p>这里的逻辑是：</p>
<ol>
<li>**采样的是 $\pi$**：系统根据模型 1 的预测去“猜”哪些物品能进前 $q_1$ 名。这是一个随机过程。</li>
<li><strong>优化的是 Groundtruth 的通过率</strong>：我们有一个固定的目标 $\mathbf{y}$（比如商品 A 和 C 是好的）。我们希望调整模型参数，使得在上面的采样过程中，$\pi$ 恰好总是选中 A 和 C。</li>
<li><strong>结果</strong>：如果 $\pi$ 选中了 A 和 C，并且模型 2 也给了高分，那么 $CE$ Loss 就会很小。</li>
</ol>
<p><strong>总结一句话</strong>：我们在用 $CE$ Loss 强迫模型 1 生成的随机采样分布 $P_\pi$，尽可能地与真实的 Groundtruth 分布（永远选中好商品）重合。<br><img src="/2025/12/21/LCRON/image-2.png"></p>
<h1 id="离散-Top-K-算子的矩阵表达解析"><a href="#离散-Top-K-算子的矩阵表达解析" class="headerlink" title="离散 Top-K 算子的矩阵表达解析"></a>离散 Top-K 算子的矩阵表达解析</h1><h2 id="1-设定场景"><a href="#1-设定场景" class="headerlink" title="1. 设定场景"></a>1. 设定场景</h2><p><strong>背景</strong>：假设有 4 个物品（Item 1, Item 2, Item 3, Item 4），模型 $\mathcal{M}$ 给它们打的分数向量 $x$ 是：<br>$$x &#x3D; [10, \mathbf{90}, 50, \mathbf{80}]$$<br>（注意：Item 2 是 90 分，Item 4 是 80 分，它是前两名）。</p>
<p><strong>目标</strong>：我们现在的目标是：找出 Top-2 的物品（也就是 $k&#x3D;2$）。</p>
<hr>
<h2 id="2-什么是“排列矩阵”-mathcal-P-？"><a href="#2-什么是“排列矩阵”-mathcal-P-？" class="headerlink" title="2. 什么是“排列矩阵” $\mathcal{P}$？"></a>2. 什么是“排列矩阵” $\mathcal{P}$？</h2><p>文本里说：“$(\mathcal{P}<em>x^{\downarrow})</em>{i,j}&#x3D;1$ 表示 $x_j$ 是 $x$ 中第 $i$ 大的元素”。</p>
<p>这句话翻译成人话就是：<strong>矩阵的第 $i$ 行，用来指示“第 $i$ 名是谁”</strong>。</p>
<p>我们来看看排名的实际情况：</p>
<ul>
<li>**第 1 名 ($i&#x3D;1$)**：是 90 分（在原数组的第 2 个位置）。</li>
<li>**第 2 名 ($i&#x3D;2$)**：是 80 分（在原数组的第 4 个位置）。</li>
<li>**第 3 名 ($i&#x3D;3$)**：是 50 分（在原数组的第 3 个位置）。</li>
<li>**第 4 名 ($i&#x3D;4$)**：是 10 分（在原数组的第 1 个位置）。</li>
</ul>
<p>根据这个排名，我们构建排列矩阵 $\mathcal{P}$（每一行对应第 1 名到第 4 名的位置）：<br>$$\mathcal{P} &#x3D;<br>\begin{pmatrix}<br>0 &amp; \mathbf{1} &amp; 0 &amp; 0 \<br>0 &amp; 0 &amp; 0 &amp; \mathbf{1} \<br>0 &amp; 0 &amp; 1 &amp; 0 \<br>1 &amp; 0 &amp; 0 &amp; 0<br>\end{pmatrix}<br>\begin{matrix}<br>\leftarrow \text{第1行：第1名在位置2} \<br>\leftarrow \text{第2行：第2名在位置4} \<br>\leftarrow \text{第3行：第3名在位置3} \<br>\leftarrow \text{第4行：第4名在位置1}<br>\end{matrix}$$</p>
<hr>
<h2 id="3-那个求和公式-sum-是在干嘛？"><a href="#3-那个求和公式-sum-是在干嘛？" class="headerlink" title="3. 那个求和公式 $\sum$ 是在干嘛？"></a>3. 那个求和公式 $\sum$ 是在干嘛？</h2><p>文中给出的公式是：<br>$$\mathcal{M}<em>i^{\downarrow}(k) &#x3D; \sum</em>{j&#x3D;1}^{k} (\mathcal{P}<em>{\mathcal{M}}^{\downarrow})</em>{j, :}$$</p>
<p>这其实就是<strong>把矩阵的前 $k$ 行加起来</strong>。</p>
<p>现在我们要选 Top-2 ($k&#x3D;2$)，所以我们只看矩阵的前两行：</p>
<ul>
<li><strong>第 1 行（冠军）</strong>：$[0, 1, 0, 0]$</li>
<li><strong>第 2 行（亚军）</strong>：$[0, 0, 0, 1]$</li>
</ul>
<p>把它们加起来：<br>$$[0, 1, 0, 0] + [0, 0, 0, 1] &#x3D; [0, \mathbf{1}, 0, \mathbf{1}]$$</p>
<hr>
<h2 id="4-结果解读"><a href="#4-结果解读" class="headerlink" title="4. 结果解读"></a>4. 结果解读</h2><p>最后得到的这个向量 $[0, \mathbf{1}, 0, \mathbf{1}]$ 就是公式里的 $\mathcal{M}_i^{\downarrow}(k)$。它是一个<strong>掩码（Mask）</strong>：</p>
<ul>
<li><strong>第 1 个位置是 0</strong> $\rightarrow$ Item 1 没选中</li>
<li><strong>第 2 个位置是 1</strong> $\rightarrow$ Item 2 选中了</li>
<li><strong>第 3 个位置是 0</strong> $\rightarrow$ Item 3 没选中</li>
<li><strong>第 4 个位置是 1</strong> $\rightarrow$ Item 4 选中了</li>
</ul>
<hr>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这段看似复杂的数学描述，其实只干了一件事：</p>
<ol>
<li><strong>排序</strong>：看看谁的分数高。</li>
<li><strong>制表</strong>：造一个矩阵记录第几名原本在哪里。</li>
<li><strong>圈地</strong>：如果我要 Top-K，我就把表里的前 K 行拿出来，并在对应位置打勾。</li>
</ol>
<hr>
<h2 id="为什么要搞这么复杂？"><a href="#为什么要搞这么复杂？" class="headerlink" title="为什么要搞这么复杂？"></a>为什么要搞这么复杂？</h2><p>最后那句“松弛为随机变量…进行优化”才是重点。因为硬生生的排序（Sort）和取前 K 个（Top-K）是<strong>不可导的操作</strong>（没法求梯度，没法训练神经网络）。</p>
<p>作者把它写成矩阵形式，是为了后面把这个“由0和1组成的硬矩阵”变成“<strong>软绵绵的概率矩阵</strong>”（比如用 Gumbel-Softmax 或 NeuralSort），这样就可以放进神经网络里反向传播了。</p>
<p><img src="/2025/12/21/LCRON/image-1.png"></p>
<h2 id="1-场景设定"><a href="#1-场景设定" class="headerlink" title="1. 场景设定"></a>1. 场景设定</h2><p><strong>背景</strong>：一家公司要招人。</p>
<ul>
<li>**阶段 1 ($\mathcal{M}_1$)**：HR 简历筛选。<ul>
<li><strong>任务</strong>：从一堆简历里选出 $q_1$ 个人进入下一轮。</li>
<li><strong>对应公式中的</strong> $P_{\mathcal{M}_1}^{q_1}$（HR 给每个人通过的概率）。</li>
</ul>
</li>
<li>**阶段 2 ($\mathcal{M}_2$)**：业务主管面试。<ul>
<li><strong>任务</strong>：从 HR 选送的人里，选出 $q_2$ 个人发 Offer。</li>
<li><strong>对应公式中的</strong> $P_{\mathcal{M}_2}^{q_2}$（主管给每个人打的分）。</li>
</ul>
</li>
<li>**目标 ($\mathbf{y}$)**：我们希望真正的人才（Ground Truth, $y&#x3D;1$）能拿到 Offer。</li>
</ul>
<hr>
<h2 id="2-核心概念解释"><a href="#2-核心概念解释" class="headerlink" title="2. 核心概念解释"></a>2. 核心概念解释</h2><h3 id="A-P-pi-：HR-的选择结果（采样概率）"><a href="#A-P-pi-：HR-的选择结果（采样概率）" class="headerlink" title="A. $P_{\pi}$：HR 的选择结果（采样概率）"></a>A. $P_{\pi}$：HR 的选择结果（采样概率）</h3><p>你在图中间看到的那个带 $\prod$ 的大公式，是在计算<strong>“某一种特定的入围名单”出现的概率</strong>。</p>
<ul>
<li><strong>假设有 3 个候选人</strong>：小王（牛人）、小李（混子）、小张（混子）。</li>
<li><strong>HR 的打分（概率）</strong>：小王(0.9), 小李(0.6), 小张(0.1)。</li>
<li>**我们要选 2 个人 ($q_1&#x3D;2$)**。<ul>
<li>**组合 $\pi_1$ (小王, 小李)**：概率很高，因为两人分都高。</li>
<li>**组合 $\pi_2$ (小李, 小张)**：概率很低，因为小张分太低了。</li>
</ul>
</li>
</ul>
<h3 id="B-P-CS-q-2-：最终生存概率（期待值）"><a href="#B-P-CS-q-2-：最终生存概率（期待值）" class="headerlink" title="B. $P_{CS}^{q_2}$：最终生存概率（期待值）"></a>B. $P_{CS}^{q_2}$：最终生存概率（期待值）</h3><p>你在图下方看到的那个带 $\mathbb{E}$ 的公式，是在算<strong>“小王最终拿到 Offer 的平均概率”</strong>。<br>这个概率取决于两件事：</p>
<ol>
<li>HR 得先把小王放进来（取决于 $P_{\pi}$）。如果 HR 没选小王，主管根本见不到他，得分为 0。</li>
<li>主管得给小王打高分（取决于 $P_{\mathcal{M}_2}^{q_2}$）。</li>
</ol>
<h3 id="C-CE-P-CS-q-2-mathbf-y-：交叉熵-Loss"><a href="#C-CE-P-CS-q-2-mathbf-y-：交叉熵-Loss" class="headerlink" title="C. $CE(P_{CS}^{q_2}, \mathbf{y})$：交叉熵 Loss"></a>C. $CE(P_{CS}^{q_2}, \mathbf{y})$：交叉熵 Loss</h3><p>这就是标准的奖惩机制。</p>
<ul>
<li>**如果小王是牛人 ($y&#x3D;1$)**：我们需要 $P_{CS}^{q_2}$ 越接近 1 越好。</li>
<li><strong>如果小王没拿到 Offer</strong>：Loss 就会变大。</li>
</ul>
<hr>
<h2 id="3-举个具体的数字例子（全流程）"><a href="#3-举个具体的数字例子（全流程）" class="headerlink" title="3. 举个具体的数字例子（全流程）"></a>3. 举个具体的数字例子（全流程）</h2><p>假设 $y_{小王} &#x3D; 1$ (小王是真正的人才)。</p>
<h3 id="情景一：模型配合得很好"><a href="#情景一：模型配合得很好" class="headerlink" title="情景一：模型配合得很好"></a>情景一：模型配合得很好</h3><ul>
<li>**阶段 1 (HR)**：给小王打了高分。</li>
<li><strong>结果</strong>：在大多数可能的组合 $\pi$ 里，小王都在名单上。</li>
<li>**阶段 2 (主管)**：给小王打了高分（比如 0.95）。</li>
<li><strong>计算期望</strong>：期望分数 $\approx$ (小王在名单里的概率 0.9) $\times$ (主管打分 0.95) &#x3D; 0.855。</li>
<li><strong>计算 Loss</strong>：$Loss &#x3D; -1 \times \ln(0.855) &#x3D; \mathbf{0.15}$ (Loss 很小，模型很开心)。</li>
</ul>
<h3 id="情景二：阶段-1-掉链子了（漏斗问题）"><a href="#情景二：阶段-1-掉链子了（漏斗问题）" class="headerlink" title="情景二：阶段 1 掉链子了（漏斗问题）"></a>情景二：阶段 1 掉链子了（漏斗问题）</h3><ul>
<li>**阶段 1 (HR)**：眼拙，觉得小王不行，给了低分。</li>
<li><strong>结果</strong>：小王很难进入名单 $\pi$。他在大多数情况下被“截断”了。</li>
<li>**阶段 2 (主管)**：虽然主管模型很准，但是他没机会见到小王。</li>
<li><strong>在那些小王没入选的组合里</strong>，小王的得分被 Mask 成了 0。</li>
<li><strong>计算期望</strong>：期望分数 $\approx$ (小王在名单里的概率 0.1) $\times$ (主管打分 0.95) &#x3D; 0.095。</li>
<li><strong>计算 Loss</strong>：$Loss &#x3D; -1 \times \ln(0.095) &#x3D; \mathbf{2.35}$ (Loss 巨大！)。</li>
</ul>
<hr>
<h2 id="4-这个-Loss-的妙处（Back-Propagation）"><a href="#4-这个-Loss-的妙处（Back-Propagation）" class="headerlink" title="4. 这个 Loss 的妙处（Back Propagation）"></a>4. 这个 Loss 的妙处（Back Propagation）</h2><p>当发生了情景二（Loss 巨大）时，梯度反向传播会告诉模型：<br>“喂！最后结果不对！小王是牛人，但他没拿到分！”</p>
<p>这时候，责任会通过数学公式分摊：</p>
<ul>
<li><strong>主管模型 ($\mathcal{M}_2$) 说</strong>：“这不怪我啊，我如果见到他肯定给高分，但我没见到啊！”</li>
<li><strong>HR 模型 ($\mathcal{M}_1$) 就会收到强烈的梯度信号</strong>：“是你前面没把他选进来！ 下次把小王的 $P_{\mathcal{M}_1}$ 提上去！”</li>
</ul>
<p>这就是<strong>“端到端代理 Loss”</strong>的核心意义：<br>它通过最终的胜负（是否 Recall 成功），跨过中间的采样过程，直接去优化前面的粗排模型，让粗排模型知道：“凡是后面精排模型喜欢的，你前面都要给我放进来，别误杀”。</p>
<h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><p>冲突是怎么发生的？假设我们要选出 Top-2（金牌和银牌），而球员 A 和球员 B 都是顶级天才（Ground-truth $y_A&#x3D;1, y_B&#x3D;1$）。模型的宏伟目标：希望 A 和 B 都能进入前两名。<br>梯度的指令：</p>
<ul>
<li>指令 1：把 A 往“第一名”的位置推（增加 $\hat{P}_{1,A}$）。</li>
<li>指令 2：把 B 也往“第一名”的位置推（增加 $\hat{P}_{1,B}$）。<br>因为“第一名只能给一个人”的硬约束（求和等于 1），这两个指令是完全相反的。为了让 A 的概率上升，模型必须牺牲 B。<br>后果：模型在训练时会感到“左右为难”，梯度信号一会儿让 A 冲，一会儿让 B 冲，导致参数更新抵消，训练极其不稳定。</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://2010727302.github.io/2025/08/11/prediction/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar4.jpg">
      <meta itemprop="name" content="Yuhan Wang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="一个田螺突然就">
      <meta itemprop="description" content="Yuhan Wang's Blog">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 一个田螺突然就">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/08/11/prediction/" class="post-title-link" itemprop="url">prediction</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2025-08-11 20:00:51 / 修改时间：20:13:15" itemprop="dateCreated datePublished" datetime="2025-08-11T20:00:51+08:00">2025-08-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/research/" itemprop="url" rel="index"><span itemprop="name">research</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="ctr预估"><a href="#ctr预估" class="headerlink" title="ctr预估"></a>ctr预估</h2><h3 id="顶层范式对比：判别式-vs-生成式"><a href="#顶层范式对比：判别式-vs-生成式" class="headerlink" title="顶层范式对比：判别式 vs. 生成式"></a><strong>顶层范式对比：判别式 vs. 生成式</strong></h3><table>
<thead>
<tr>
<th align="left">维度</th>
<th align="left">传统判别式方法 (Discriminative)</th>
<th align="left">新兴生成式方法 (Generative)</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong>核心目标</strong></td>
<td align="left">学习一个决策边界，直接预测一个标签的条件概率 $P(Y|X)$。<br /><strong>示例</strong>：“给定特征X，用户点击Y的概率是多少？”</td>
<td align="left">学习数据的联合分布 $P(X, Y)$ 或其生成过程。<br />模型旨在理解数据的底层结构与机制，而不仅仅是对数据点进行区分。</td>
</tr>
<tr>
<td align="left"><strong>解决的问题</strong></td>
<td align="left"><strong>数值预测与排序</strong>：<br />- 直接对CTR&#x2F;CVR等指标进行精确的数值预测。<br />- 核心优化目标为AUC、Logloss等排序或校准指标。</td>
<td align="left"><strong>机制理解、序列生成与特征表示</strong>：<br />- 端到端序列推荐，直接生成推荐列表。<br />- 为下游任务生成高阶、具有语义的特征表示。<br />- 通过模拟数据生成过程，进行数据增强或偏差校准。<br />- 对用户行为或市场动态进行仿真与归因分析。</td>
</tr>
<tr>
<td align="left"><strong>代表模型&#x2F;技术</strong></td>
<td align="left"><strong>特征交互模型</strong>: Wide &amp; Deep, DeepFM, DCN, xDeepFM<br /><strong>用户序列模型</strong>: DIN, DIEN<br /><strong>多任务&#x2F;偏差校正</strong>: ESMM, PLE<br /><strong>集成模型</strong>: XGBoost, LightGBM</td>
<td align="left"><strong>完全生成式架构</strong>: HSTU, OneRec<br /><strong>混合式&#x2F;特征增强架构</strong>: LUM, HLLM<br /><strong>数据增强&#x2F;分布建模</strong>: VAE, GAN</td>
</tr>
<tr>
<td align="left"><strong>主要优势</strong></td>
<td align="left"><strong>高效性与精确性</strong>：在特定预测任务上计算效率高，经过长期优化，预测精度有保障。<br /><strong>技术成熟度高</strong>：工业界有大量成熟的应用、优化经验和稳定的部署方案。</td>
<td align="left"><strong>统一多阶段流程</strong>: 完全生成式架构能替代传统多阶段漏斗，解决目标不一致问题。<br /><strong>语义理解与泛化</strong>: 能基于内容理解进行推荐，有效缓解数据稀疏和冷启动问题。<br /><strong>提供过程可解释性</strong>：通过模拟生成路径，为归因分析和反事实推断提供了可能性。</td>
</tr>
<tr>
<td align="left"><strong>主要挑战</strong></td>
<td align="left"><strong>模型可解释性差</strong>：通常被视为“黑箱”，难以对单个预测结果进行归因。<br /><strong>强数据依赖性</strong>：在历史交互数据稀疏或缺失的场景下（如冷启动），模型效果会显著下降。<br /><strong>偏差敏感性</strong>：容易学习并放大训练数据中存在的各种偏差（如选择偏差、位置偏差）。</td>
<td align="left"><strong>计算与工程成本高</strong>：生成式大模型的训练和在线推理成本通常远高于判别式模型，对硬件资源要求高。<br /><strong>建模复杂度高</strong>：需要将业务流程抽象为生成过程，对建模能力要求更高。<br /><strong>技术尚处发展阶段</strong>：大规模、成熟的工业界应用相对较少，许多方案仍在快速迭代和探索中。</td>
</tr>
</tbody></table>
<hr>
<h3 id="主流判别式CTR-CVR模型详细比较"><a href="#主流判别式CTR-CVR模型详细比较" class="headerlink" title="主流判别式CTR&#x2F;CVR模型详细比较"></a><strong>主流判别式CTR&#x2F;CVR模型详细比较</strong></h3><table>
<thead>
<tr>
<th align="left">模型类别</th>
<th align="left">代表模型</th>
<th align="left">核心创新点</th>
<th align="left">解决的主要问题</th>
<th align="left">优势</th>
<th align="left">权衡&#x2F;挑战</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong>特征交互模型</strong></td>
<td align="left"><strong>Wide &amp; Deep, DeepFM</strong></td>
<td align="left">结合浅层（记忆）和深层（泛化）网络，或将FM与DNN结合。</td>
<td align="left">平衡模型的记忆能力和泛化能力，自动学习低阶和高阶特征交互 [1]。</td>
<td align="left">效果稳健，易于实现。</td>
<td align="left">MLP部分特征交互是隐式的，效率和可解释性一般。</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><strong>DCN, xDeepFM</strong></td>
<td align="left">设计显式的交叉网络（Cross Network）或压缩交互网络（CIN）来建模高阶特征交互。</td>
<td align="left">更高效、更有针对性地学习高阶特征交互，避免MLP的“暴力”学习。</td>
<td align="left">参数效率高，能显式控制交互阶数，有一定可解释性。</td>
<td align="left">交互模式相对固定，可能不如注意力机制灵活。</td>
</tr>
<tr>
<td align="left"><strong>用户序列模型</strong></td>
<td align="left"><strong>DIN (Deep Interest Network)</strong></td>
<td align="left">引入注意力机制，根据目标广告动态激活用户历史行为序列中的相关兴趣。</td>
<td align="left">解决传统池化方法无法捕捉用户兴趣多样性和上下文相关性的问题 [2]。</td>
<td align="left">显著提升对用户动态兴趣的捕捉能力，模型更具上下文感知能力。</td>
<td align="left">注意力计算与序列长度成正比，长序列下面临性能瓶颈。</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><strong>DIEN (Deep Interest Evolution Network)</strong></td>
<td align="left">在DIN基础上引入GRU，显式建模用户兴趣的演化过程和时序依赖。</td>
<td align="left">捕捉用户兴趣的发展趋势，而不仅仅是静态的相关性。</td>
<td align="left">能更深刻地理解用户兴趣的演化链路，预测更具时效性。</td>
<td align="left">模型结构更复杂，训练成本更高。</td>
</tr>
<tr>
<td align="left"><strong>多任务学习框架</strong></td>
<td align="left"><strong>ESMM (Entire Space Multi-task Model)</strong></td>
<td align="left">在全曝光空间上联合建模pCTR和pCTCVR，间接推导pCVR。</td>
<td align="left">从根本上解决了CVR预估中的样本选择偏差（SSB）问题 [3]。</td>
<td align="left">理论优雅，效果显著，已成为CVR预估的工业标准范式。</td>
<td align="left">依赖于 $pCVR &#x3D; pCTCVR &#x2F; pCTR$ 的假设，任务间信息共享机制简单。</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><strong>PLE (Progressive Layered Extraction)</strong></td>
<td align="left">设计解耦的共享专家和任务独有专家网络，并进行渐进式信息提取。</td>
<td align="left">解决多任务学习中普遍存在的“跷跷板”现象（负迁移）[4]。</td>
<td align="left">有效缓解任务间冲突，提升多任务学习的整体性能和稳定性。</td>
<td align="left">架构设计和调优相对复杂。</td>
</tr>
<tr>
<td align="left"><strong>迁移学习框架</strong></td>
<td align="left"><strong>Transfer Learning (Fine-tuning)</strong></td>
<td align="left">利用在数据丰富的源域（如所有广告）上预训练的模型，在数据稀疏的目标域（如特定广告位）上进行微调 [5, 6]。</td>
<td align="left">解决冷启动和数据稀疏问题，校准由选择偏差导致的有偏预测 [5]。</td>
<td align="left">有效利用已有知识，提升稀疏场景下的模型性能和泛化能力。</td>
<td align="left">需要仔细设计迁移策略，防止负迁移；源域和目标域的差异性是关键。</td>
</tr>
</tbody></table>
<hr>
<h3 id="1-生成式架构-Generative-Architecture"><a href="#1-生成式架构-Generative-Architecture" class="headerlink" title="1. 生成式架构 (Generative Architecture)"></a><strong>1. 生成式架构 (Generative Architecture)</strong></h3><ul>
<li>LLM4Rec 范式概览<br> <img src="/2025/08/11/prediction/llm4rec.png"><br><em>A Survey on Large Language Models for Recommendation：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2305.19860">https://arxiv.org/pdf/2305.19860</a></em>	<br>如上图，LLM4Rec 概括来说有3种范式：</li>
</ul>
<ol>
<li>   LLM Embedding + RS：利用语言模型作为特征提取器，将 user 和 item 的描述输入给 LLM 然后得到 embedding，然后再将这些 embedding 输入到传统推荐模型使用（小红书 NoteLLM）<br><em>案例：小红书笔记推荐，利用 LLM 产生笔记 embedding 然后做 i2i 召回；</em></li>
<li>   LLM Tokens + RS：利用语言模型的输出对 RS 进行辅助增强（谷歌 Youtube、华为 KAR）<br><em>案例：谷歌 Youtube 利用 LLM 产生指导兴趣标签，然后从传统推荐模型结果里只筛选出兴趣标签内的；</em></li>
<li>   LLM As RS：直接将语言模型作为推荐系统，大致分为三类：<br>  a.	将推荐视为文本生成任务，文本结果即推荐结果：P5、VIP5、M6-Rec<br>  b.	基于 LLM 的生成式推荐：Meta GR（2024’02）<br>  c.	改造传统推荐模型并变大，展现 Scaling Law 规律：Meta Wukong（2024’03）<br><em>案例：阿里 M6-Rec 将推荐任务全部转化成文本，用户特征、物料都用文本描述，最后可以直接生成文本进行推荐。</em></li>
</ol>
<hr>
<h3 id="各模型详细解析"><a href="#各模型详细解析" class="headerlink" title="各模型详细解析"></a><strong>各模型详细解析</strong></h3><h4 id="传统判别式推荐模型-DLRM"><a href="#传统判别式推荐模型-DLRM" class="headerlink" title="传统判别式推荐模型 (DLRM)"></a><strong>传统判别式推荐模型 (DLRM)</strong></h4><ul>
<li><strong>模型概述</strong>：这是工业界最成熟和广泛应用的一类模型，其核心目标是学习一个判别函数 $P(y|x)$，即在给定用户和物品的特征后，预测一个具体的分数，如点击率（CTR）或转化率（CVR）。</li>
<li><strong>技术架构</strong>：经典架构通常是“输入层 + Embedding层 + 特征交互层 + MLP层”。Embedding层将高维稀疏的ID特征映射为低维稠密向量；特征交互层通过点积、交叉网络（如DCN）或注意力机制（如DIN）来学习特征间的组合关系；MLP层则进行非线性变换并输出最终预测值。</li>
<li><strong>优势与挑战</strong>：优势在于技术成熟、预测精准、易于部署。挑战在于模型是“黑箱”，难以解释；严重依赖历史数据，泛化和冷启动能力弱；并且多阶段的推荐漏斗存在目标不一致和信息损失问题。</li>
</ul>
<h4 id="完全生成式"><a href="#完全生成式" class="headerlink" title="完全生成式"></a><strong>完全生成式</strong></h4><h5 id="1-1-HSTU-Meta"><a href="#1-1-HSTU-Meta" class="headerlink" title="1.1 HSTU (Meta)"></a><strong>1.1 HSTU (Meta)</strong></h5><ul>
<li><p><strong>模型概述</strong>：HSTU将推荐彻底范式化为一个序列到序列（Seq2Seq）的生成任务。模型根据用户历史直接<strong>生成</strong>未来可能交互的物品ID序列。</p>
<p>  <img src="/2025/08/11/prediction/hstu.png"></p>
  <img src="hstu2.png" alt="image-20250809191048418" style="zoom:50%;" />
</li>
<li><p><strong>具体做法</strong> </p>
<p>  这篇是 GR 架构的示范，直接把推荐 task 转为序列转导问题，用 HSTU 编码器串起所有交互行为</p>
<ul>
<li>将所有用户行为、上下文和物品特征统一编码为事件序列。 </li>
<li>采用为推荐场景定制的高效Transformer变体<strong>HSTU</strong>架构，自回归地预测下一个事件（物品）。</li>
<li>将模型参数规模扩展至万亿级别，首次在推荐领域验证了<strong>Scaling Law</strong>的有效性。</li>
</ul>
</li>
<li><p><strong>优势</strong> </p>
<ul>
<li>彻底抛弃多阶段pipeline，实现端到端优化，解决目标不一致问题。 </li>
<li>能够建模更长、更完整的用户行为序列。</li>
<li>超大规模模型可能涌现出更深层次的用户理解能力。</li>
</ul>
</li>
<li><p><strong>挑战</strong></p>
<ul>
<li>算力要求高、在线延迟高、无法利用交叉特征</li>
</ul>
</li>
</ul>
<h5 id="1-2-OneRec-快手"><a href="#1-2-OneRec-快手" class="headerlink" title="1.2 OneRec (快手)"></a><strong>1.2 OneRec (快手)</strong></h5><ul>
<li><strong>模型概述</strong>：同样采用端到端生成范式，统一多阶段流程，直接生成推荐的视频ID序列。</li>
<li><strong>技术架构与实现</strong>：核心技术包括<strong>视频Tokenizer</strong>（将视频压缩为语义ID）和引入**强化学习(RL)**（通过DPO等方法对齐多业务目标）以及采用Encoder-Decoder结构，并引入MoE提升效率。</li>
<li><strong>优势</strong>：<ol>
<li>极大地简化了系统架构，显著降低了运营成本。</li>
<li>通过RL，能更灵活地对齐长期、复杂的业务指标。</li>
</ol>
</li>
<li><strong>挑战</strong>：<ol>
<li>语义ID的质量直接决定了生成效果，设计和迭代成本高。</li>
<li>面临生成无效ID或热门ID的问题，强依赖奖励模型进行约束。</li>
</ol>
</li>
</ul>
<hr>
<h4 id="2-堆叠式架构-Stacked-Architecture"><a href="#2-堆叠式架构-Stacked-Architecture" class="headerlink" title="2. 堆叠式架构 (Stacked Architecture)"></a><strong>2. 堆叠式架构 (Stacked Architecture)</strong></h4><h5 id="2-1-Large-User-Model-LUM-阿里"><a href="#2-1-Large-User-Model-LUM-阿里" class="headerlink" title="2.1 Large User Model - LUM (阿里)"></a><strong>2.1 Large User Model - LUM (阿里)</strong></h5><img src="lum1.png" alt="image-20250809190735326" style="zoom:80%;" />

<ul>
<li><p><strong>模型概述</strong>：LUM代表了一种务实的融合路径，其核心思想是“用生成式模型赋能传统的判别式模型”，而非完全替代。</p>
</li>
<li><img src="lum2.png" alt="image-20250809190735326" style="zoom:80%;" />
</li>
<li><p><strong>技术架构与实现</strong>：</p>
<ul>
<li>阶段1:以充足的各式各样的用户行为作为语料，构造通用的LUM，理解搜推广下的语言体系&amp;协同信号。同时承担Scaling Law的能力。注意此时LUM是下游任务无关的。</li>
<li>阶段2:通过构造不同trigger，来提取与下游强相关的Knowledge。达到生成式-&gt;判别式转换目的，适配下游各种应用</li>
<li>阶段3:以增量信号的方式引入到各个生产模型中去</li>
</ul>
</li>
<li><p><strong>优势</strong>：</p>
<ol>
<li>无需重构现有系统，落地成本低，风险可控。</li>
<li>利用了生成式模型的泛化能力，同时保留了判别式模型的高效和精准。</li>
</ol>
</li>
<li><p><strong>挑战与权衡</strong>：</p>
<ol>
<li>多阶段串行优化（预训练-&gt;查询-&gt;排序），增加了系统链路的复杂性和迭代成本。</li>
<li>生成式预训练的目标与下游判别式任务的目标可能不完全一致。</li>
</ol>
</li>
</ul>
<h5 id="2-2-HLLM-字节"><a href="#2-2-HLLM-字节" class="headerlink" title="2.2 HLLM (字节)"></a><strong>2.2 <a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/fVgqAL-pO6Ae5CwcPf34yA">HLLM (字节)</a></strong></h5><ul>
<li><p><strong>模型概述</strong>：用LLM彻底替代了传统的、无语义的ID Embedding。</p>
<img src="hllm.png" alt="图片" style="zoom: 60%;" />
</li>
<li><p><strong>技术架构与实现</strong>：做了一个双LLM结构：</p>
<ul>
<li>Item LLM 用文本描述建模物品（标题、标签等），下游可以直接拿 emb用</li>
<li>User LLM 则接历史物品 emb序列，学习用户兴趣 ➜ 预测下一个物品<br>两个 LLM 分开训练，既节省 token 长度，又保留了预训练能力。</li>
</ul>
</li>
<li><p><strong>优势与创新点</strong>：</p>
<ol>
<li>将推荐从基于ID的“符号匹配”升级为基于内容的“语义理解”。</li>
<li>解决冷启动：对新物品，只要有文本描述就能立即进行高质量推荐。</li>
</ol>
</li>
<li><p><strong>挑战与权衡</strong>：</p>
<ol>
<li>模型效果高度依赖物品是否有高质量、信息丰富的文本描述。</li>
<li>双LLM架构的训练和推理成本依然很高。</li>
</ol>
</li>
</ul>
<hr>
<h4 id="3-混合式架构-Hybrid-Architecture"><a href="#3-混合式架构-Hybrid-Architecture" class="headerlink" title="3. 混合式架构 (Hybrid Architecture)"></a><strong>3. 混合式架构 (Hybrid Architecture)</strong></h4><h5 id="3-1-MTGR-美团-MTGR：美团外卖生成式推荐Scaling-Law落地实践"><a href="#3-1-MTGR-美团-MTGR：美团外卖生成式推荐Scaling-Law落地实践" class="headerlink" title="3.1 [MTGR (美团)](MTGR：美团外卖生成式推荐Scaling Law落地实践)"></a><strong>3.1 [MTGR (美团)](<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/JiDOqD-ThU0Upp6xnNg3Nw">MTGR：美团外卖生成式推荐Scaling Law落地实践</a>)</strong></h5><p><img src="http://mmecoa.qpic.cn/sz_mmecoa_png/hEx03cFgUsXMsNLia4ic6hfqwSCxWCibscN2UtUxpA7QvCyP4YYIjJcS5rgP0fkkGdnNzbknqFKJFFhmtDeg5cptg/640?wx_fmt=png&from=appmsg&tp=wxpic&wxfrom=10005&wx_lazy=1&retryload=3" alt="图1 外卖推荐DLRM范式下Scaling路径"></p>
<img src="http://mmecoa.qpic.cn/sz_mmecoa_png/hEx03cFgUsXMsNLia4ic6hfqwSCxWCibscNbAJv949gFXqMQSgDabUI8OJf7yiaIp7ic3PCWKd95WwZbvTMafiaOiasKg/640?wx_fmt=png&from=appmsg&tp=wxpic&wxfrom=10005&wx_lazy=1&retryload=3" alt="图2 MTGR模型架构图" style="zoom:80%;" />

<ul>
<li><p>在模型方面是微创新，主要创新是在推理阶段，而这也是为了落地而做。推理阶段就是深度使用Nvidia的feature，挖掘和发挥其GPU的推理能力。</p>
<p>  比HSTU微创新有：</p>
<p>  （1）保留交叉特征：将用户特征、历史行为序列、实时交互和候选者特征（包括交叉特征）转化为统一令牌序列，交叉特征被整合进候选者令牌中。 </p>
<p>  （2）组层归一化：按领域分组对不同领域的token进行归一化，确保每个领域内的token分布相似，通常调整为均值0、方差1的分布，从而在自注意力计算前对齐不同领域的语义空间。</p>
<p>  （3）动态掩码策略：MTGR模型用来处理令牌序列的一种方法，主要目的是避免信息泄露，同时提升模型性能。它的核心思想是根据令牌的类型和时间关系，灵活控制哪些令牌可以“看到”其他令牌的信息。</p>
<p>  推理阶段的创新有：</p>
<p>  （1）通过集成Nvidia提供的深度优化的Cutlass-based HSTU kernel，支持变长序列的输入无需padding，</p>
<p>  大幅提升了Attention的计算效率，单算子性能相较于Triton版本提升2~3倍。</p>
<p>  （2）引入动态BS，每张卡的BS根据实际数据的序列长度动态调整，保证计算量（total_tokens）基本相同。因为少数用户的序列很长，大部分用户的序列都比较短，每张卡拿到的用户数相同，但由于序列长度不同实际的计算量差别较大。而每个step都要等负载最重的卡计算完，所有卡才能进行梯度同步。</p>
<p>  （3）选择TensorRT作为模型推理框架：TensorRT是Nvidia推出的推理优化框架，在业界广泛应用，具有较强的算子融合、低精度量化能力。</p>
<p>  ab效果：</p>
<p>  转换量提升 1.22%，点击率（CTR）提升 1.31%。同时，训练成本保持不变，推理成本降低 12%。</p>
</li>
</ul>
<hr>
<h4 id="4-判别式扩展架构-Discriminative-Scaling"><a href="#4-判别式扩展架构-Discriminative-Scaling" class="headerlink" title="4. 判别式扩展架构 (Discriminative Scaling)"></a><strong>4. 判别式扩展架构 (Discriminative Scaling)</strong></h4><h5 id="4-1-RankMixer-抖音"><a href="#4-1-RankMixer-抖音" class="headerlink" title="4.1 RankMixer (抖音)"></a><strong>4.1 <a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/IxyUzNKF9piNvrEOSGgnTg">RankMixer (抖音)</a></strong></h5><ul>
<li><p>作者认为，深度学习推荐模型（DLRMs）的扩展定律研究必须克服以下问题：</p>
<ul>
<li>架构应与硬件对齐，以最大化现代GPU上的MFU和计算吞吐量。</li>
<li>模型设计必须利用推荐数据的特性，如数百个字段之间的异构特征空间和个性化跨特征交互。</li>
</ul>
<p>  这两个问题对应了RankMixer的两大模块：</p>
<ul>
<li>对输入特征进行tokenizer，用token操作代替特征交叉；</li>
<li>用稀疏MoE代替self-attention，扩大参数的同时保证并行度，使得RankMixer在相同的FLOPS下具有更大的模型容量和学习能力。</li>
</ul>
  <img src="E:\RUCGL\REPO\--\images\rankmixer.png" alt="image-20250809223504933" style="zoom:67%;" />
</li>
<li><p>输入特征被分词为T个语义相关的特征令牌（tokens），通过L层RankMixer块处理。每层包括2部分：</p>
<ol>
<li>多头令牌混合（Multi-head Token Mixing）：无参数操作，通过拆分头（heads）并重组令牌，实现跨令牌特征交互。比自注意力更高效，避免了异构特征空间的相似度计算难题。<br>  具体的，用户、item、交叉等特征构建的连续的每个特征field（embedding）是被当作token，那么所有特征field就是一个token序列，也可以看作是一个shape是（T，D）的矩阵。将列分块成（T，H<em>D&#x2F;H)的矩阵。然后转换为shape是（H，T</em>D&#x2F;H）的矩阵。那么现在的每个token（每一行）就有原生每个特征field（token）的一部分。可以简单理解为，后续对该token的任何操作都是对所有特征field的操作。</li>
<li>每令牌前馈网络（Per-token FFNs）：为每个令牌分配独立参数，处理特征子空间建模，避免高频特征主导长尾信号。扩展为Sparse-MoE变体，使用动态路由（ReLU Routing + Dense-Training&#x2F;Sparse-Inference）解决专家不均衡和欠训练问题，提高ROI。</li>
</ol>
</li>
</ul>
<p>RankMixer 和 DeepSeek 都使用了稀疏专家混合（MoE），这是近年来高效大模型的热门技术。DeepSeek 的 MoE（如 DeepSeek V3）在 NLP 领域广为人知，而 RankMixer 将 MoE 适配到推荐系统，优化了路由策略（如 ReLU Routing）以处理特征不均衡。</p>
<p>AB：</p>
<p>* 部署于抖音Feed推荐（1B参数），活跃天数+0.2%、App时长+0.5%；低活跃用户提升最大（活跃天数+0.46%）。</p>
<p>* 在广告（ADVV+3.9%）和搜索（活跃天数+0.14%、查询修改率-1%）场景中也显著提升，验证通用性。</p>
<p>心得：</p>
<p>（1）多头令牌混合，实现了重组令牌，输出每个令牌是所有特征field的小部分组成的，换句话说，对该令牌的后续操作就是对所有特征field的特征交叉。对所有新令牌的处理，就是一种并行处理。这个借鉴MLP-Mixer。</p>
<p>（2）每令牌前馈网络，为每个特征field设置独立的网络，并且使用很多expert网络，这些都增大了模型的规模和weights数量。但是通过动态策略、稀疏MOE，即路由到少量的expert上，实现了效率的可控。这很像deepseek的优化。</p>
<h3 id="模型核心对比总览表"><a href="#模型核心对比总览表" class="headerlink" title="模型核心对比总览表"></a>模型核心对比总览表</h3><table>
<thead>
<tr>
<th align="left">技术路径</th>
<th align="left">模型&#x2F;机构</th>
<th align="left">核心思想</th>
<th align="left">核心贡献&#x2F;价值</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong>基线</strong></td>
<td align="left">传统判别式模型</td>
<td align="left">为“用户-物品”对进行精准打分和排序。</td>
<td align="left">奠定了深度学习推荐的基础，在特定预测任务上高效且成熟。</td>
</tr>
<tr>
<td align="left"><strong>生成式架构</strong></td>
<td align="left"><strong>HSTU (Meta)</strong></td>
<td align="left">将推荐重构为序列到序列的<strong>内容生成</strong>问题。</td>
<td align="left">首次在工业界验证了推荐系统的“ Scaling Law ”。</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><strong>OneRec (快手)</strong></td>
<td align="left">用<strong>端到端的统一生成模型</strong>替代多阶段推荐漏斗。</td>
<td align="left">提供了一套完整的、可落地的端到端生成式推荐系统方案。</td>
</tr>
<tr>
<td align="left"><strong>堆叠式架构</strong></td>
<td align="left"><strong>LUM (阿里)</strong></td>
<td align="left"><strong>“生成式赋能判别式”</strong>：用生成模型离线构建知识，增强传统模型。</td>
<td align="left">无需重构现有系统，落地成本低，风险可控。</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><strong>HLLM (字节)</strong></td>
<td align="left">用<strong>层级化LLM</strong>替代传统ID Embedding，实现端到端的语义化。</td>
<td align="left">将推荐从“符号匹配”升级为“语义理解”。</td>
</tr>
<tr>
<td align="left"><strong>混合式架构</strong></td>
<td align="left"><strong>MTGR (美团外卖)</strong></td>
<td align="left">借鉴生成式架构(HSTU)作为<strong>统一特征编码器</strong>，兼容全部特征进行判别式任务预估。</td>
<td align="left">既利用了Transformer强大的序列编码能力，又保留了交叉特征等被验证有效的判别式信息。</td>
</tr>
<tr>
<td align="left"><strong>判别式扩展架构</strong></td>
<td align="left"><strong>RankMixer (抖音)</strong></td>
<td align="left">在判别式范式内，通过<strong>软硬协同设计</strong>实现模型的极致扩展。</td>
<td align="left">证明了通过架构创新，判别式模型同样能实现规模化效应。</td>
</tr>
</tbody></table>
<hr>
<h3 id="CTR模型近期工作"><a href="#CTR模型近期工作" class="headerlink" title="CTR模型近期工作"></a>CTR模型近期工作</h3><table>
<thead>
<tr>
<th align="left">研究方向</th>
<th align="left">模型&#x2F;论文名称</th>
<th align="left">核心思想与贡献</th>
<th align="left">应用与验证</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong>建模用户行为</strong></td>
<td align="left"><strong>MIRRN</strong> (Multi-granularity Interest Retrieval and Refinement Network)(KDD2025) [1]</td>
<td align="left">通过检索不同时间尺度的行为子序列来捕获用户的多粒度兴趣。引入多头傅里叶变换器高效学习序列关系。</td>
<td align="left">在多个基准任务上效果显著，并通过华为音乐A&#x2F;B测试验证，提升了用户听歌量和时长。</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><strong>LIBER</strong> (Lifelong User Behavior Modeling Based on Large Language Models) [2]</td>
<td align="left">提出包含用户行为流分区、用户兴趣学习和融合三个模块的框架，利用大语言模型(LLMs)处理终身用户行为序列。有效解决了长序列信息提取和用户兴趣动态变化的挑战。</td>
<td align="left">已部署在华为音乐推荐服务中，用户播放次数提升3.01%，播放时长提升7.69%。</td>
</tr>
<tr>
<td align="left"><strong>建模特征交叉</strong></td>
<td align="left"><strong>IPA</strong> (Towards Unifying Feature Interaction Models) [3]</td>
<td align="left">提出了一个名为IPA的通用框架，通过交互函数、层池化和层聚合器三个组件来统一现有特征交互模型。并基于该框架提出了一个有竞争力的新型模型。</td>
<td align="left">基于该框架的新模型PFL在腾讯广告平台的A&#x2F;B测试中获得显著GMV提升，并已在多个场景部署。</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><strong>OptFusion</strong> (Fusion Matters: Learning Fusion in Deep CTR Models)(WSDM2025) [4]</td>
<td align="left">提出OptFusion方法，通过一次性学习算法自动化学习CTR模型中的融合连接和操作，解决了传统融合策略固化的问题。</td>
<td align="left">在三个大规模数据集上的实验证明了其有效性和高效性。</td>
</tr>
<tr>
<td align="left"><strong>集成架构</strong></td>
<td align="left"><strong>CETNet</strong> (A Collaborative Ensemble Framework for CTR Prediction) [5]</td>
<td align="left">提出协同集成训练网络，让多个拥有独立嵌入表的模型协同学习，并通过基于置信度的融合机制动态平衡各模型贡献。</td>
<td align="left">在Amazon、淘宝、快手及Meta的大规模工业数据集上验证了其有效性。</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><strong>MBCnet</strong> (Multi-Branch Cooperation Network) [6]</td>
<td align="left">提出多分支协同网络，包含三个不同功能的网络分支。通过“分支共同教学”和“适度差异化”原则让多分支协作，以更好地建模复杂特征交互。</td>
<td align="left">在淘宝的大规模工业数据集和在线A&#x2F;B测试中，CTR、交易量和GMV均取得显著提升。</td>
</tr>
<tr>
<td align="left"><strong>蒸馏机制</strong></td>
<td align="left"><strong>EKTF</strong> (Ensemble Knowledge Transfer Framework) [7]</td>
<td align="left">针对大规模集成学习的局限性，提出集成知识迁移框架。利用学生网络的集体决策作为抽象教师指导学习，并设计考核机制平衡超参数。</td>
<td align="left">在五个真实数据集上的实验结果表明其在有效性和兼容性方面均优于现有方法。</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><strong>FSDNet</strong> (Feature Interaction Fusion Self-Distillation Network) [8]</td>
<td align="left">提出一个融合自蒸馏模块，在每一层连接显式和隐式特征交互。利用最深的融合层作为教师，通过自蒸馏指导浅层训练，避免了复杂的师生框架设计。</td>
<td align="left">在四个基准数据集上验证了框架的有效性和泛化能力。</td>
</tr>
<tr>
<td align="left"><strong>大语言模型相关</strong></td>
<td align="left"><strong>RAG-Enhanced LLM Recommender with Multi-Head Early Exit</strong> [9]</td>
<td align="left">结合检索增强生成(RAG)和多头早退出机制来优化LLM推荐系统的效率和精度。利用图卷积网络(GCNs)加速检索，并根据预测置信度动态终止推理过程。</td>
<td align="left">实验证明，该架构能在不牺牲精度的前提下有效减少计算时间，为LLM商业部署设立新标杆。</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><strong>MSD</strong> (LLM-Infused Approach for Optimized CTR Prediction) [10]</td>
<td align="left">提出一个LLM融合框架(MSD)，通过提取和蒸馏LLMs中的关键语义信息，并将其集成到更小更高效的模型中，以平衡效率和效果。</td>
<td align="left">在美团赞助搜索系统的在线A&#x2F;B测试中，CPM和CTR显著优于基线模型。</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><strong>FLIP</strong> (Fine-grained Alignment between ID-based Models and PLMs) [11]</td>
<td align="left">提出FLIP方法，通过新颖的联合掩码建模任务，实现表格ID与词语token之间的细粒度特征级对齐，结合了基于ID的模型和预训练语言模型(PLMs)的优势。</td>
<td align="left">在三个真实世界数据集上的实验表明，FLIP超越了现有的SOTA基线模型。</td>
</tr>
<tr>
<td align="left"><strong>跨域推荐</strong></td>
<td align="left"><strong>Enhancing CTR Prediction with Search Query Representation</strong> [12]</td>
<td align="left">利用搜索领域的用户搜索查询来增强推荐领域的用户偏好建模。引入扩散模型解决数据稀疏性问题，以推断正样本。</td>
<td align="left">实验分析表明，该模型在推荐领域的表现优于现有的最新模型。</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><strong>MLORA</strong> (Multi-Domain Low-Rank Adaptive Network) [13]</td>
<td align="left">提出多领域低秩自适应网络，为每个领域设计专门的LoRA模块，以提升模型在多领域CTR预测任务中的性能，同时避免参数量剧增。</td>
<td align="left">在多个多领域数据集和实际生产环境的A&#x2F;B测试中验证了其优越性和灵活性。</td>
</tr>
</tbody></table>
<hr>
<h4 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h4><p>[1] <strong>Multi-granularity Interest Retrieval and Refinement Network for Long-Term User Behavior Modeling in CTR Prediction</strong><br>    * <code>https://arxiv.org/abs/2411.15005</code></p>
<p>[2] <strong>LIBER: Lifelong User Behavior Modeling Based on Large Language Models</strong><br>    * <code>https://arxiv.org/abs/2411.14713</code> </p>
<p>[3] <strong>Towards Unifying Feature Interaction Models for Click-Through Rate Prediction</strong><br>    * <code>https://arxiv.org/abs/2411.12441</code> [cite: 94]</p>
<p>[4] <strong>Fusion Matters: Learning Fusion in Deep Click-through Rate Prediction Models</strong><br>    * <code>https://arxiv.org/abs/2411.15731</code> [cite: 115]</p>
<p>[5] <strong>A Collaborative Ensemble Framework for CTR Prediction</strong><br>    * <code>https://arxiv.org/abs/2411.13700</code> </p>
<p>[6] <strong>Branches, Assemble! Multi-Branch Cooperation Network for Large-Scale Click-Through Rate Prediction at Taobao</strong><br>    * <code>https://arxiv.org/abs/2411.13057</code> </p>
<p>[7] <strong>Ensemble Learning via Knowledge Transfer for CTR Prediction</strong><br>    * <code>https://arxiv.org/abs/2411.16122</code> </p>
<p>[8] <strong>Feature Interaction Fusion Self-Distillation Network For CTR Prediction</strong><br>    * <code>https://arxiv.org/abs/2411.07508</code> </p>
<p>[9] <strong>The Efficiency vs. Accuracy Trade-off: Optimizing RAG-Enhanced LLM Recommender Systems Using Multi-Head Early Exit</strong><br>    * <code>https://arxiv.org/abs/2501.02173</code> </p>
<p>[10] <strong>Balancing Efficiency and Effectiveness: An LLM-Infused Approach for Optimized CTR Prediction</strong><br>    * <code>https://arxiv.org/abs/2412.06860</code></p>
<p>[11] <strong>FLIP: Fine-grained Alignment between ID-based Models and Pretrained Language Models for CTR Prediction</strong><br>    * <code>https://arxiv.org/abs/2310.19453</code><br>[12] <strong>Enhancing CTR Prediction in Recommendation Domain with Search Query Representation</strong><br>    * <code>https://arxiv.org/abs/2410.21487</code> </p>
<p>[13] <strong>MLORA: Multi-Domain Low-Rank Adaptive Network for Click-Through Rate Prediction</strong><br>    * <code>https://arxiv.org/abs/2408.08913</code> </p>
<h4 id="ICML’25-从特征交互到特征生成：CTR预测模型的生成范式"><a href="#ICML’25-从特征交互到特征生成：CTR预测模型的生成范式" class="headerlink" title="ICML’25 | 从特征交互到特征生成：CTR预测模型的生成范式"></a><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/6F30T1QU7Mzg6N4PWDB_Yw">ICML’25 | 从特征交互到特征生成：CTR预测模型的生成范式</a></h4><h5 id="论文解决的问题"><a href="#论文解决的问题" class="headerlink" title="论文解决的问题"></a><strong>论文解决的问题</strong></h5><p>传统点击率（CTR）预测模型基于特征交互估计用户点击物品的概率，遵循判别范式，但存在原始特征嵌入的局限性，易导致嵌入维度崩溃和信息冗余问题，且由于特征间无明确顺序，难以将其转化为生成范式。</p>
<h5 id="1-论文的创新点"><a href="#1-论文的创新点" class="headerlink" title="1. 论文的创新点"></a><strong>1. 论文的创新点</strong></h5><ul>
<li>提出一种用于CTR模型的新型监督特征生成框架，将判别式的“特征交互”范式转变为生成式的“特征生成”范式。具体做法是将所有特征嵌入拼接来预测每个特征嵌入。</li>
<li>此框架可以和现有的CTR模型结合提升性能，产生维度崩溃更少、冗余更低的特征嵌入，缓解判别范式的固有局限。</li>
</ul>
<p>简单来说：</p>
<ul>
<li>以FM为例，原始的方式是特征i和特征j进行交互，改进后是生成的特征i和原始的特征j交互。</li>
<li>生成方式是用所有的特征拼接后经过MLP来生成。</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://2010727302.github.io/2025/01/27/IAS/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar4.jpg">
      <meta itemprop="name" content="Yuhan Wang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="一个田螺突然就">
      <meta itemprop="description" content="Yuhan Wang's Blog">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 一个田螺突然就">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/01/27/IAS/" class="post-title-link" itemprop="url">IAS</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2025-01-27 17:28:45 / 修改时间：17:30:03" itemprop="dateCreated datePublished" datetime="2025-01-27T17:28:45+08:00">2025-01-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/research/" itemprop="url" rel="index"><span itemprop="name">research</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Optimally-Integrating-Ad-Auction-into-E-Commerce-Platforms"><a href="#Optimally-Integrating-Ad-Auction-into-E-Commerce-Platforms" class="headerlink" title="Optimally Integrating Ad Auction into E-Commerce Platforms"></a>Optimally Integrating Ad Auction into E-Commerce Platforms</h1><p>IAS（Integrated Ad System）模型即集成广告系统模型，用于描述电商平台上广告与有机搜索结果混合排列的情况。该模型的目标函数和约束条件设计紧密围绕电商平台关注的核心指标，旨在平衡广告收入与用户体验。</p>
<ol>
<li><strong>目标函数</strong><ul>
<li><strong>收入（Revenue）</strong>：$Revenue &#x3D;\int_{V} \sum_{i \in A} p_{i}(v) w_{i} x_{i}(v) f(v) dv$，此公式表示收入是对所有广告商品的支付价格、质量因子、分配情况以及概率分布进行积分求和。其中，$p_{i}(v)$是广告商品$i$的支付价格，$w_{i}$为其质量因子，$x_{i}(v)$代表分配规则，$f(v)$是概率分布函数。通过这一函数计算，反映出平台从广告投放中获取的即时收入 。</li>
<li><strong>商品交易总量（GMV）</strong>：$GMV&#x3D;\int_{V}\left[\sum_{i \in A} g_{i} w_{i} x_{i}(v)+\sum_{i \in O} g_{i} w_{i} x_{i}(v)\right] f(v) dv$，该公式计算的是平台的商品交易总量，考虑了广告商品和有机商品的预估交易量、质量因子和分配情况。其中，$g_{i}$为商品$i$的预估交易量，对广告商品和有机商品分别求和再积分，体现了平台业务的整体交易规模，是衡量用户体验和平台长期收益的重要指标。</li>
<li><strong>无约束问题（Unconstrained Problem）</strong>：$UCST (\alpha)$给定加权系数$\alpha \in[0,1]$，通过线性凸组合收入和GMV来构建目标函数，即$max _{x \in \mathcal{X}} \alpha \cdot Revenue +(1-\alpha) \cdot GMV$。该目标函数旨在在不同权重下，同时考虑收入和GMV，寻找能使两者综合效益最大化的机制。例如，当$\alpha$接近1时，更注重收入；当$\alpha$接近0时，则更倾向于GMV。<br> Unconstrained Problem $UCST (\alpha)$ ) Given the weighted coefficient $\alpha \in[0,1]$ ,the unconstrained problem $UCST (\alpha)$ ) can be written as<br> $max _{x \in \mathcal{X}} \alpha \cdot Revenue +(1-\alpha) \cdot Volume. (4)$</li>
<li><strong>约束问题（Constrained Problem）</strong>：$CST(V_{0})$给定GMV阈值$V_{0}$，以优化收入为目标，即$max Revenue$，同时需满足$GMV \geq V_{0}$和$x \in \mathcal{X}$的约束。此目标函数强调在保证一定GMV水平的前提下，最大化广告收入，体现了平台在平衡用户体验和短期收益时的考量。<br> Constrained Problem $CST(V_{0})$ ) Given a threshold $V_{0}$ , the constrained problem $CST(V_{0})$ ) can be written as<br> $$max Revenue \quad (P1)$$<br> $$s.t. Volume \geq V_{0} \quad(C 1.1)$$<br> $$x \in \mathcal{X} \quad(C 1.2)$$</li>
</ul>
</li>
<li><strong>约束条件</strong><ul>
<li><strong>分配规则约束</strong>：对于分配规则$x_{ik}(b)$需满足$\sum_{k} x_{ik}(b) \leq 1, \forall i \in A \cup O$，确保每个商品最多被分配到一个展示位；$\sum_{i \in A} x_{ik}(b)+\sum_{i \in O} x_{ik}(b)&#x3D;1, \forall k$，保证每个展示位都有且仅有一个商品；$x_{ik}(b) \in{0,1}, \forall i, k$，表示商品是否被分配到展示位只能是0或1的二元选择。这些约束保证了分配的合理性和唯一性 。</li>
<li><strong>个体理性（Individual Rationality）</strong>：$U_{i}(x, p, b_{i}) \geq 0, \forall b_{i} \in[0, u_{i}], \forall i \in A$，此约束确保广告商参与拍卖的期望效用非负，即广告商在平台的广告投放行为能获得至少为零的收益，这是吸引广告商参与的基本条件。</li>
<li><strong>贝叶斯激励兼容（Bayesian Incentive Compatibility）</strong>：$U_{i}(x, p, v_{i}) \geq U_{i}(x, p, b_{i}), \forall b_{i} \in[0, u_{i}], \forall i \in A$，该约束保证广告商如实报告自身价值是最优策略，避免广告商虚假报价，维护拍卖机制的公平性和有效性。</li>
</ul>
</li>
</ol>
<h2 id="无约束问题-UCST-alpha"><a href="#无约束问题-UCST-alpha" class="headerlink" title="无约束问题$UCST(\alpha)$"></a>无约束问题$UCST(\alpha)$</h2><ul>
<li><strong>目标函数</strong>：$max <em>{x \in \mathcal{X}} \alpha \cdot Revenue+(1 - \alpha)\cdot GMV(4)$。这里的$\alpha\in[0,1]$是加权系数，用于平衡对收入和GMV的侧重程度。<br>   转化为<strong>引理 2</strong>:要最大化目标函数 （4），机制需要最大化目标<br> $$\int</em>{V} \sum_{i \in I}\left(\alpha \phi_{i}\left(v_{i}\right)+(1-\alpha) g_{i}\right) w_{i} x_{i}(v) f(v) d v-\alpha \sum_{i \in I} U_{i}(x, p, 0) . (5)$$</li>
<li><strong>修正虚拟价值排序</strong>：机制$M$涉及到定义修正虚拟价值$\psi_{i}(v_{i})&#x3D;(\alpha \phi_{i}(v_{i})+(1 - \alpha)g_{i})w_{i}&#x3D;(1 - \alpha)g_{i}w_{i}$。其中$\phi_{i}(v_{i})$是广告商品$i$的虚拟价值，$g_{i}$是商品$i$的预估交易量，$w_{i}$是商品$i$的质量因子。按照这个修正虚拟价值对所有商品（包括广告商品和有机商品）进行排序。</li>
<li><strong>定价规则</strong>(迈尔森)：有机商品的支付为0，广告商品的支付价格是根据其在排序中的位置和相关价值计算得出的，以保证个体理性（广告商参与拍卖的期望效用非负）和贝叶斯激励兼容（广告商如实报告自身价值是最优策略）。<br>   给定分配规则和支付规则，广告项目 i 的出价为$b_{i}$时的预期效用可以表示为：$$U_{i}\left(x, p, b_{i}\right)&#x3D;\int_{V_{-i}}\left(v_{i}-p_{i}\left(b_{i}, v_{-i}\right)\right) w_{i} x_{i}\left(b_{i}, v_{-i}\right) f_{-i}\left(v_{-i}\right) d v_{-i}$$<br>   因为$p(b)$只出现在$U_{i}(x,p,0)$中，并且我们需要保证（IR）的性质，根据引理 1，如果我们选择$p_{i}(v)&#x3D;v_{i}-\frac{\int_{0}^{v_{i}} x_{i}(s_{i},v_{-i})ds_{i}}{x_{i}(v)}$作为支付规则，那么$U_{i}(x,p,0)$将为 0，并且我们只需要考虑选择合适的$x(b)$来最大化式（5）的第一部分。</li>
<li><strong>分配规则</strong>：将广告商品插入有机商品序列进行分配。对于分配规则$x_{ik}(b)$，要满足$\sum_{k}x_{ik}(b)\leq1,\forall i\in A\cup O$（每个商品最多被分配到一个展示位）、$\sum_{i\in A}x_{ik}(b)+\sum_{i\in O}x_{ik}(b) &#x3D; 1,\forall k$（每个展示位都有且仅有一个商品）和$x_{ik}(b)\in{0,1},\forall i,k$（商品是否被分配到展示位是二元选择）等条件。<br>   对于分配规则，我们将 $\psi_{i}(v_{i}) \stackrel{ def }{&#x3D;}(\alpha \phi_{i}(v_{i})+(1-\alpha) g_{i}) w_{i}$ 定义为物品 $i$ 的修正虚拟价值。不难验证，以下分配规则可以最大化公式（5）的第一部分。<br>$x_{i k}(v)&#x3D; \begin{cases}1 &amp; 如果\psi_{i}\left(v_{i}\right)是第 k 高的修正虚拟价值，k\in{1,2,\ldots,K}。\0&amp;否则。\end{cases}$</li>
</ul>
<h2 id="约束问题-CST-V-0-商业化率约束"><a href="#约束问题-CST-V-0-商业化率约束" class="headerlink" title="约束问题$CST(V_{0})$ -商业化率约束"></a>约束问题$CST(V_{0})$ -商业化率约束</h2><p>可通过对偶转为无约束问题</p>
<ul>
<li><strong>放宽约束条件</strong>：由于可行域是离散的，即$x_{i k}(v)$不是关于出价$v$的连续函数，因此很难直接优化目标。我们首先将约束$x_{i k}(v)∈{0,1}$在（C1.2）中放宽为$x_{i k}(v)∈[0,1]$，并将放宽后的可行域记为$\bar{x}$。放宽后的约束问题为：<br>最大化$$R(x)\stackrel{ def }{&#x3D;}\int_{V}\sum_{i\in I}w_{i}p_{i}(v)x_{i}(v)f(v)dv（P2）$$<br>约束条件为$$V(x)\stackrel{ def }{&#x3D;}\int_{V}\sum_{i\in I}g_{i}w_{i}x_{i}(v)f(v)dv\geq V_{0}（C2.1）$$<br>$$x\in\overline{\mathcal{X}}（C2.2）$$</li>
<li><strong>对偶问题</strong>：对于可访问的$V_{o}$，强对偶性成立意味着<br>$$\begin{aligned}&amp;\underbrace{\max_{x:x\in\mathcal{X},V(x)\geq V_{0}}R(x)}<em>{\text{原始问题}}&#x3D;\underbrace{\min</em>{\lambda\geq0}\max_{x\in\mathcal{X}}\left(R(x)+\lambda\left(V(x)-V_{0}\right)\right)}<em>{\text{对偶问题}}\&amp;&#x3D;\min</em>{\lambda\geq0}\max_{x\in\mathcal{X}}\left[\int_{V}\sum_{i\in I}\left(p_{i}\left(b_{i}\right)+\lambda g_{i}\right)w_{i}x_{i}(b)f(b)db-\lambda V_{0}\right]。\end{aligned}$$</li>
<li><strong>分配规则</strong>：当给定一个$\lambda$时，它是一个具有松弛可行域$\bar{x}$的无约束问题。由于$\bar{x}$的系数矩阵是完全单模矩阵([22])，内部问题的最优解是整数形式，即 0-1 形式。因此，内部问题的最优解可以通过机制 M 以$\alpha &#x3D; 1&#x2F;(\lambda + 1)$获得，即<br>$$ x_{i k}^{\lambda}(v)&#x3D;\begin{cases}1&amp;\text{如果}\psi_{i}^{\lambda}\left(v_{i}\right)\text{是第}k\text{高的，}k\in{1,2,\ldots,K},\0&amp;\text{否则，}\end{cases}$$<br>其中$\psi_{i}^{\lambda}(v_{i})\stackrel{def}{&#x3D;}[(\phi_{i}(v_{i})+\lambda g_{i})w_{i}]&#x2F;(\lambda + 1)$。</li>
<li><strong>定价规则</strong>：$p_{i}^{\lambda}(v)$可以通过在(7)中将$x_{i k}(v)$替换为$x_{i k}^{\lambda}(v)$得到。</li>
<li><strong>$\lambda$计算</strong>：二分<br><img src="/./images/lambda.png" alt="alt text"></li>
<li><strong>定理 2</strong>：具有阈值$V_0$的约束问题等价于一个具有系数$\alpha^{<em>}$的无约束问题，其中$\alpha^{</em>}&#x3D;1&#x2F;(\lambda^{<em>}+1)$，并且$\lambda^{</em>}$是约束问题中的最优拉格朗日乘子。</li>
</ul>
<h2 id="广告数量约束"><a href="#广告数量约束" class="headerlink" title="广告数量约束"></a>广告数量约束</h2><ol>
<li><strong>问题设定</strong>：在集成广告系统中引入对广告商品总数的限制，要求广告商品数量不超过 $c$ ，即 $\sum_{i \in A} \sum_{k} x_{ik}(v) \leq c$，将此约束加入原有的约束条件集 $x$ 后得到新的可行域 $x’$。</li>
<li><strong>无约束问题的最优机制</strong>：基于此前无约束问题的结论，商品按修正虚拟价值 $\psi_{i}(v_{i})$ 排序。在新约束下，为保证广告商品数量符合预算，在排序时仅考虑排名前 $c$ 的广告商品。由此得到扩展机制 $M’(c)$，具体步骤为：<ul>
<li>将所有广告商品按 $\psi_{i}(v_{i})$ 降序排列，保留前 $c$ 个广告商品，删除其余广告商品；</li>
<li>针对剩余的广告商品和所有有机商品，运行系数为 $\alpha$ 的原无约束问题机制 $M$。</li>
<li>由于原机制 $M$ 的最优性以及对广告商品数量的有效控制，$M’(c)$ 是当前设定下无约束问题的最优机制。</li>
</ul>
</li>
<li><strong>约束问题的求解</strong>：对于约束问题，其求解逻辑与前文类似，但由于新可行域 $x’$ 的系数矩阵不再是全幺模矩阵，导致求解难度增加。通过将其转化为最小费用最大流问题（证明见附录 Lemma 6），可证明松弛问题仍具有0 - 1形式的最优解。基于此，约束问题仍能通过选择合适参数转化为无约束问题求解，从而将此前针对无约束和约束问题关系的结论（Theorem 2）扩展到存在广告数量预算约束的场景。</li>
</ol>
<h2 id="广告间隔约束"><a href="#广告间隔约束" class="headerlink" title="广告间隔约束"></a>广告间隔约束</h2><p>用广告数量约束的机制，分别运行局部的无约束问题</p>
<h3 id="PC端"><a href="#PC端" class="headerlink" title="PC端"></a>PC端</h3><ul>
<li><p><strong>页面划分</strong>：当我们在电子商务平台上通过个人电脑搜索产品时，搜索结果通常显示为几行，每行包含几个项目。受这种布局的启发，我们希望限制每行中的广告数量以让用户感到舒适。鉴于此，我们将一个搜索结果页面分成多行，每行包含连续的 l 个槽位。然后，我们要求在这 l 个槽位中显示的广告项目最多为 c 个。我们将这个模型称为稀疏集成广告系统——行（SIASR）。</p>
</li>
<li><p><strong>约束条件</strong>：$$\sum_{i \in A} \sum_{k &#x3D; ml + 1}^{(m + 1)l} x_{ik}(v)≤c，m &#x3D; 0,1,\ldots,|K&#x2F;l|$$<br>$$\sum_{i \in A} \sum_{k&#x3D;\lfloor K &#x2F; l] l+1}^{K} x_{i k}(v) ≤c$$。将它们添加到$x$中并表示新的约束条件。</p>
</li>
<li><p><strong>无约束问题的最优机制</strong>：基于上述分析，我们可以对每个部分运行机制(M’(c))来为稀疏集成广告系统（SIASR）生成一个可行的广告排列方案。这是因为机制(M’(c))本身具有最优性，所以每个部分都能实现最优的广告商品分配，进而使得整个页面所有展示位都能达到全局最优的分配效果。由此，我们得到了在这种设定下的最优机制，记为(\tilde{M}(c, l))。</p>
<ul>
<li><strong>第一步</strong>：运行机制(M’(c))，对所有商品（包括广告商品和自然商品）分配前(l)个展示位。机制(M’(c))会根据商品的相关价值对商品进行排序，并依据广告商品数量预算(c)，从所有商品中选择合适的商品分配到这(l)个展示位上。</li>
<li><strong>第二步</strong>：运行机制(M’(c))，对剩余的所有商品分配接下来的(l)个展示位。在完成第一步分配后，剩余商品的集合发生了变化，再次运行机制(M’(c))，从这些剩余商品中选择合适的商品填充接下来的(l)个展示位。</li>
<li><strong>第三步</strong>：重复第二步，直到所有展示位都分配完毕。需要注意的是，在最后一轮分配时，展示位的数量可能会小于(l)。这是因为前面按照每(l)个展示位一轮进行分配，到最后可能会剩下不足(l)个展示位，此时依然按照机制(M’(c))对剩余商品进行分配，以完成整个搜索结果页面的广告与自然商品的分配。</li>
</ul>
</li>
<li><p><strong>约束问题</strong>：我们通过引理 7（在附录中显示）克服了这个问题。到目前为止，我们解决了 SIASR 的受约束问题，并将定理 2 扩展到了这种情况。<br>引理 7.对于 SIASR，约束问题的松弛内问题可以构造为最小费用最大流问题，并且具有 0-1 形式的最优解。</p>
</li>
</ul>
<h3 id="移动端"><a href="#移动端" class="headerlink" title="移动端"></a>移动端</h3><ul>
<li><p><strong>页面划分</strong>：一般来说，输入一个关键字后，搜索结果在一列中显示（与个人电脑终端的布局不同）。如果我们仍然想限制广告的稀疏性，我们需要在任何连续的 l 个位置上添加约束，即任何连续的 l 个位置上最多显示 c 个广告项。</p>
</li>
<li><p><strong>约束条件</strong>：$\sum_{i∈A}\sum_{k &#x3D; m + 1}^{m + l}x_{ik}(v)\leq c$，$m &#x3D; 0,1,\ldots,K - l$，并将新的可行区域表示为$\hat{x}$。我们将这个模型称为稀疏集成广告系统——列（SIASC）。</p>
</li>
<li><p><strong>无约束问题的最优机制</strong>：</p>
</li>
</ul>
<ol>
<li>运行机制$M’(c)$以在所有物品上分配前$l$个时段。</li>
<li>运行机制$M’(c - a)$，为所有剩余物品分配下一个时段，其中$a$是最后$l - 1$个时段中的广告物品数量。</li>
<li>重复步骤 2，直到所有槽位都被分配。</li>
</ol>
<ul>
<li><strong>约束问题</strong>：对于约束问题，我们可以将 SIASR 中使用的方法扩展到这种设置。唯一的区别是，在这种设置下，连续的 l 个槽有更多的约束。然而，最终它并不影响难度。我们只需要稍微修改一下图 6 的结构：添加一定数量的节点$k_{i}$来代表更多的组，并连接弧$s_{j}^{\prime\prime}k_{i}$，其中$j\in{i,i + 1,\cdots,i + l - 1}$，以及弧$k_{i}t$。其他分析是相似的。这样，我们将定理 2 推广到 SIASC 的情况。</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://2010727302.github.io/2025/01/04/mixed-ranking/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar4.jpg">
      <meta itemprop="name" content="Yuhan Wang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="一个田螺突然就">
      <meta itemprop="description" content="Yuhan Wang's Blog">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 一个田螺突然就">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/01/04/mixed-ranking/" class="post-title-link" itemprop="url">混排</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-01-04 14:11:04" itemprop="dateCreated datePublished" datetime="2025-01-04T14:11:04+08:00">2025-01-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-01-27 17:26:45" itemprop="dateModified" datetime="2025-01-27T17:26:45+08:00">2025-01-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/research/" itemprop="url" rel="index"><span itemprop="name">research</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="NMA-Neural-Multi-slot-Auctions-with-Externalities-for-Online-Advertising"><a href="#NMA-Neural-Multi-slot-Auctions-with-Externalities-for-Online-Advertising" class="headerlink" title="NMA: Neural Multi-slot Auctions with Externalities for Online Advertising"></a>NMA: Neural Multi-slot Auctions with Externalities for Online Advertising</h1><ul>
<li><strong>研究背景</strong>：在线广告是众多互联网平台的主要收入来源，拍卖机制的设计对平台、用户和广告商至关重要。广义第二价格（GSP）拍卖是常见机制，但存在用户点击假设与实际不符等问题。如在美团外卖平台，广告展示受多种因素影响，而GSP未考虑这些外部性。Deep Neural Auctions（DNA）虽有改进，但仍有局限，VCG及其变体WVCG在理论上可处理外部性，但在实践中面临收入下降或参数求解复杂等问题。</li>
<li><strong>研究目的</strong>：提出一种新的神经多槽拍卖机制（NMA），有效建模全局外部性，平衡平台收入和社会福利，同时解决现有机制的问题。</li>
<li><strong>方法与模型</strong><ul>
<li><strong>模型结构</strong><ul>
<li><strong>上下文感知列表式预测模块（CLPM）</strong>：采用参数共享结构，输入广告列表及相关公共信息，通过嵌入层、自注意力单元和目标注意力单元处理，输出列表式pCTR。还提出基于广告真实反馈的辅助损失，使模型能有效建模全局外部性，提高预测准确性。</li>
<li><strong>列表式深度排名模块（LDRM）</strong>：结合拍卖机制与深度学习，设计μ-Net子网络计算广告列表排名分数，确定支付规则，保证激励兼容性（IC）和个体理性（IR），实现端到端优化，提高排名公式表达能力。</li>
<li><strong>列表式可微排序模块（LDSM）</strong>：将排序操作从不可微转换为可微，通过定义排序算子和放松argmax操作，输出行随机置换矩阵表示选择概率，使复杂拍卖机制能端到端训练，解决LDRM在分配和支付处理上与深度学习不适应的问题。</li>
<li><strong>社会福利最大化辅助损失</strong>：基于广告列表社会福利定义，构建辅助损失，加速学习过程，减少社会福利下降，通过调整参数平衡NMA性能，确保满足社会福利约束。</li>
</ul>
</li>
<li><strong>实验设计</strong><ul>
<li><strong>数据集</strong>：使用公共数据集Avito和工业数据集Meituan进行离线实验，将数据集按时间或比例划分为训练集和测试集。</li>
<li><strong>评估指标</strong>：包括点击率（CTR）、每千次展示收入（RPM）、每千次展示社会福利（SWPM）和社会福利最大化比率（SWMR），同时评估机制的IC属性。</li>
<li><strong>对比方法</strong>：与GSP、DNA、VCG和WVCG等代表性拍卖机制对比。</li>
</ul>
</li>
</ul>
</li>
<li><strong>实验结果</strong><ul>
<li><strong>离线实验</strong><ul>
<li><strong>性能比较</strong>：NMA在两个数据集上的RPM、SWPM和CTR指标上优于DNA和GSP，能有效建模全局外部性；与VCG相比，NMA在广告收入和社会福利间平衡更好；在RPM指标上明显优于WVCG，验证了NMA的强大表达和学习能力。NMA的IC-R值与VCG相当且优于GFP，满足IC约束。</li>
<li><strong>模块消融研究</strong>：去除CLPM、LDRM - LDSM或社会福利最大化辅助损失后的NMA变体性能均下降，证明各模块对NMA性能提升有重要作用，CLPM能有效建模全局外部性，辅助损失有助于平衡广告收入和社会福利。</li>
<li><strong>超参数分析</strong>：α₁增大时，SWPM增加但RPM下降，α₂在一定范围内增加可提升性能，过大则导致性能下降，说明辅助损失可帮助平衡收入和福利，且CLPM辅助损失权重需合理设置。</li>
</ul>
</li>
<li><strong>在线A&#x2F;B测试</strong>：在美团外卖平台进行为期一个月的在线A&#x2F;B测试，NMA相比GSP在CTR、RPM和SWPM上分别有显著提升，证明NMA在实际应用中可实现更高平台收入和社会福利，尽管在线测试与离线实验结果在绝对值上存在差异，但趋势一致。</li>
</ul>
</li>
<li><strong>研究结论</strong>：NMA有效建模全局外部性，通过设计的模块和辅助损失平衡平台收入和社会福利，在离线和在线实验中表现优异，已部署于美团外卖平台。未来可进一步优化，如采用列表生成模块替代全排列算法，提高工作效率。</li>
</ul>
<h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>在线广告拍卖为社交网络服务和电子商务平台带来了数十亿美元的收入。对于广告商来说简单易懂的广义第二价格（GSP）拍卖，几乎已成为行业中广告拍卖机制的基准。然而，大多数基于GSP的行业实践都假定用户点击仅依赖于广告本身，而忽略了外部项目的影响，即外部性。最近，深度神经网络拍卖（DNA）尝试用深度神经网络升级GSP，并在一定程度上对局部外部性进行建模。然而，它仅考虑了拍卖中的集合级上下文，而忽略了广告的顺序和展示位置，这仍然不是最优的。尽管基于维克里 - 克拉克 - 格罗夫斯（VCG）的多槽拍卖（如VCG、加权VCG（WVCG））使得对全局外部性（如广告的顺序和位置等）进行建模在理论上成为可能，但它们缺乏对收入和社会福利的有效平衡。</p>
<p>在本文中，我们提出了名为神经多槽拍卖（NMA）的新型拍卖机制，以应对上述挑战。具体而言，我们使用上下文感知列表式预测模块对全局外部性进行有效建模，以实现更好的性能。我们设计了一个列表式深度排名模块，以保证端到端学习中的激励兼容性。此外，我们提出了一个社会福利辅助损失，以在最大化收入的同时有效地减少社会福利的下降。在离线大规模数据集和在线A&#x2F;B测试中的实验结果表明，NMA在工业实践中比其他现有拍卖机制（即GSP、DNA、WVCG）获得了更高的收入，同时平衡了社会福利，并且我们已成功将NMA部署在美团外卖平台上。</p>
<h1 id="Contextual-Generative-Auction-with-Permutation-level-Externalities-for-Online-Advertising"><a href="#Contextual-Generative-Auction-with-Permutation-level-Externalities-for-Online-Advertising" class="headerlink" title="Contextual Generative Auction with Permutation-level Externalities for Online Advertising"></a><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/bXtJuava8XhjybrlTHAcCA">Contextual Generative Auction with Permutation-level Externalities for Online Advertising</a></h1><ol>
<li><strong>研究背景</strong><ul>
<li><strong>在线广告的重要性与拍卖机制</strong>：在线广告是互联网行业的核心收入来源，广告拍卖在确保平台收入和激励广告商方面起着关键作用。传统拍卖机制如GSP存在局限性，其独立CTR假设忽略了其他展示广告的影响，即外部性。</li>
<li><strong>学习型拍卖的进展与局限</strong>：学习型拍卖如Deep Neural Auction（DNA）和Score Weighted VCG（SW-VCG）虽能更好地捕捉外部性，但受“分配后预测”设计范式限制，仅考虑候选广告集内的外部性（集合级外部性），未考虑最终分配中影响每个广告CTR的顺序上下文（排列级外部性），导致分配非最优。</li>
</ul>
</li>
<li><strong>方法设计</strong><ul>
<li><strong>理论基础与问题建模</strong><ul>
<li>多槽拍卖与排列级外部性：将在线广告拍卖抽象为多槽拍卖问题，考虑广告商出价、广告特征、用户特征等因素，定义分配规则和支付规则。引入排列级外部性，即广告的CTR受其他展示广告影响，且不同排列会导致外部影响的差异。</li>
<li>最优多槽拍卖：基于Myerson拍卖理论，推导适应排列级外部性的最优拍卖机制，证明在满足一定条件下，该机制能最大化平台预期收入并满足激励兼容性（IC）和个体理性（IR）约束。</li>
<li>拍卖设计为学习问题：由于直接实现最优分配规则计算复杂，将拍卖机制参数化，通过学习确定参数。引入事后遗憾（ex-post regret）概念，以量化广告商偏离IC条件的程度，将拍卖设计问题转化为最小化预期负收入并满足事后遗憾为零的约束优化问题。</li>
</ul>
</li>
<li><strong>CGA框架设计</strong><ul>
<li><strong>生成器（Generator）</strong>：采用自回归生成模块，包括排列不变集级编码器和排列等变自回归解码器。编码器通过自注意力层和求和池化增强广告表示，解码器基于上下文嵌入学习条件概率，以生成最大化预期虚拟福利的广告序列。</li>
<li><strong>评估器（Evaluator）</strong>：预测每个广告的排列感知CTR，通过对广告序列嵌入进行双向LSTM和多头自注意力编码，结合预测阶段的逐点CTR，估计个性化外部性感知校准向量，与逐点CTR元素相乘得到排列感知CTR。</li>
<li><strong>支付计算（Payment Computation）</strong>：受神经网络在多物品拍卖中有效近似最优机制的启发，引入PaymentNet学习最优支付规则。PaymentNet的输入包括分配嵌入、自排除出价配置文件和预期价值配置文件，通过sigmoidal激活函数计算支付率，以满足IR约束并输出支付。</li>
</ul>
</li>
<li><strong>优化与训练</strong><ul>
<li>G-E框架优化：先训练Evaluator至收敛，然后冻结其参数，使用Evaluator估计的排列感知奖励通过策略梯度训练Generator，以最大化虚拟福利。</li>
<li>PaymentNet优化：在Generator和Evaluator收敛后，冻结它们的参数，应用增广拉格朗日方法解决约束优化问题，优化PaymentNet，尽管问题非凸，但实验表明优化后的CGA能接近最优收入且遗憾极小。</li>
</ul>
</li>
</ul>
</li>
<li><strong>实验验证</strong><ul>
<li><strong>实验设置</strong><ul>
<li>数据集：使用来自淘宝的真实日志数据，包括训练集和测试集，每个样本涉及多个广告商竞争广告槽位，实验设置广告槽位数为3。</li>
<li>基线方法：对比GSP、DNA、SW-VCG、VCG Auction with Permutation-level Externalities（VCG）、EdgeNet和Optimal等方法，根据外部性建模粒度分类。</li>
<li>性能指标：考虑每千次展示收入（RPM）、点击率（CTR）和IC度量（衡量广告商操纵出价可获得的效用相对增加）。</li>
<li>实现细节：设置CGA的特征嵌入大小、注意力机制、隐藏层大小等参数，通过Adam优化器训练，学习型基线方法通过网格搜索调优超参数。</li>
</ul>
</li>
<li><strong>离线比较结果</strong><ul>
<li>CGA在平台收入（RPM）和CTR方面优于现有方法，且事后遗憾较低，表明CGA能有效近似最优拍卖机制。</li>
<li>随着外部性建模从无到集合级再到排列级的改进，拍卖性能在三个指标上均有提升，突出了精细建模外部性在拍卖设计中的重要性。</li>
</ul>
</li>
<li><strong>消融研究</strong><ul>
<li>CGA的各设计考虑有效，去除Evaluator或改变训练方式会导致性能下降，证明了G-E框架、外部奖励建模和虚拟价值使用的重要性。</li>
<li>去除价值分布对CGA性能影响较小，可能是因为CGA对外部性的建模通过捕捉广告间相关性，部分反映了缺失的价值分布信息。</li>
</ul>
</li>
<li><strong>在线A&#x2F;B测试结果</strong><ul>
<li>CGA在淘宝广告系统的在线A&#x2F;B测试中表现良好，与DNA相比，RPM提升3.2%，平均响应时间仅增加3ms（相对增加1.6%），同时提高了广告商的投资回报率（ROI）、CTR和商品交易总额（GMV），表明CGA能通过生成模型有效探索分配空间，提升平台收入。</li>
</ul>
</li>
</ul>
</li>
<li><strong>研究结论</strong><ul>
<li>提出CGA框架，用于在线多槽广告拍卖中考虑排列级外部性，理论上证明了经典Myerson拍卖在适应排列级外部性时的最优性，为CGA框架设计提供依据。</li>
<li>CGA通过自回归生成模型和G-E学习范式优化分配，通过量化IC约束为预期事后遗憾学习最优支付规则，经离线和在线实验验证有效。</li>
<li>未来研究将扩展上下文生成机制，以整合来自不同渠道的异构项目。<br><img src="/2025/01/04/mixed-ranking/images/1.13_Figure_1.png" alt="alt text"><br><img src="/2025/01/04/mixed-ranking/images/1.13_Figure_2.png" alt="alt text"><br><img src="/2025/01/04/mixed-ranking/images/1.13_Figure_3.png" alt="alt text"><br><img src="/2025/01/04/mixed-ranking/images/1.13_Figure_4.png" alt="alt text"><br><img src="/2025/01/04/mixed-ranking/images/1.13_Figure_5.png" alt="alt text"><br><img src="/2025/01/04/mixed-ranking/images/1.13_Figure_6.png" alt="alt text"><br>使用真实监督信号的方式虽然简单直接，但是此类方法只考虑了初始排序这一种排列方式上的物品间关系和用户反馈。假设有序列中有n个物品，其余n!-1种排列方式都被模型忽略，不利于寻找最优排序。<br><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/TUpkUi2EpqW0wZ3KxncJYQ">refer</a></li>
</ul>
</li>
</ol>
<p>基于listwise模型的rerank的实现方法。而在listwise模型中根据做法的不同又可以分为序列生成式、基于序列表征pointwise式、半生成式、两段式和强化学习等几种不同的方案。</p>
<h1 id="model方法"><a href="#model方法" class="headerlink" title="model方法"></a>model方法</h1><h2 id="基于序列表征，pointwise打分"><a href="#基于序列表征，pointwise打分" class="headerlink" title="基于序列表征，pointwise打分"></a>基于序列表征，pointwise打分</h2><p>这一大类有一个共同的特点，都是以上层精排的输出序列作为输入，在模型结构上借助RNN等序列结构来引入item序列之间的影响。进一步的通过attention的方式来捕捉item之间的相互影响。典型的如DLCM模型。而在阿里的PRM中进一步地将用户的个性化向量通过和item结合的方式引入模型中。这些模型第二个共同特点是最终线上对item的打分还是pointwise的，直接输出序列中每个item的分数，根据分数从高到低排序。</p>
<h3 id="DLCM"><a href="#DLCM" class="headerlink" title="DLCM"></a><a target="_blank" rel="noopener" href="https://www.cnblogs.com/xumaomao/p/18213440">DLCM</a></h3><p><img src="/2025/01/04/mixed-ranking/images/DLCM.png" alt="alt text"><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/390857478">refer</a><br>DLCM模型主要包含3个步骤：</p>
<ol>
<li><p>使用传统的LTR模型检索Top N个doc，具体做法将查询-文档对 $(q,d)$ 转化特征向量 $\mathbf{x}_{(q,d)}$，然后使用全局排序函数 $f$ 计算查询 $q$ 的Top N个doc的列表 $R_q^n$</p>
</li>
<li><p>使用GRU对Top N个doc的特征向量 $\mathbf{x}_{(q,d)}$ 进行编码，从低位置到高位置，一步一步地输入进GRU中，最终产生一个隐向量 $s_n$ 和n个隐层输出 $o_i$， $i \in [1,n]$。这个局部模型被称为local context model - $I(R_q,X_q)$，输出被称为local ranking context</p>
</li>
<li><p>该步为对Top N个doc进行重排序，使用的是local ranking function (局部排序函数) $\phi$，并且该函数的输入为 $s_n$ 和 $o$</p>
</li>
</ol>
<h3 id="PRM"><a href="#PRM" class="headerlink" title="PRM"></a><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/TUpkUi2EpqW0wZ3KxncJYQ">PRM</a></h3><p><img src="/2025/01/04/mixed-ranking/images/PRM.png" alt="alt text"></p>
<ul>
<li>用transformer来克服RNN距离遗忘的问题，从而显式建模item之间的相互影响</li>
<li>在transformer中加入用户兴趣的建模 (Transformer equipped with personalized embedding)</li>
<li>其中个性化LTR Loss形式:</li>
</ul>
<p>$$\mathcal{L} &#x3D; \sum_{r\in\mathcal{R}} \ell({y_i, P(y_i|X,PV;\hat{\theta})|i\in\mathcal{S}_r})$$</p>
<p>PV矩阵会和输入模型的初始item特征矩阵拼接，PV矩阵由预训练模型(CTR预估模型)产生</p>
<ul>
<li><a href="#PRM%E5%85%B7%E4%BD%93%E6%A8%A1%E5%9E%8B">具体模型</a></li>
</ul>
<h4 id="Challenges"><a href="#Challenges" class="headerlink" title="Challenges"></a>Challenges</h4><ul>
<li>重排序后的评分困难：无法为每个反事实列表获取反馈</li>
<li>指数级时间复杂度：组合优化问题，存在n!种可行排列</li>
</ul>
<h4 id="评估生成范式"><a href="#评估生成范式" class="headerlink" title="评估生成范式"></a>评估生成范式</h4><ul>
<li>评估器(Evaluator)：Evaluate listwise utility</li>
<li>生成器(Generator)：Generate feasible permutations</li>
</ul>
<h3 id="SetRank"><a href="#SetRank" class="headerlink" title="SetRank"></a>SetRank</h3><h2 id="序列生成"><a href="#序列生成" class="headerlink" title="序列生成"></a>序列生成</h2><p>上面的那些方法都是基于预估分数重排，而下面的这些方法主要利用 RNN 直接生成重排序。</p>
<h3 id="seq2slate"><a href="#seq2slate" class="headerlink" title="seq2slate"></a>seq2slate</h3><p>考虑了前序信息，通过 RNN 来提取前序信息，再通过 pointer network 来从输入商品列表中一步步地生成最终推荐列表。训练时采用 REINFORCE 算法去训练，并且用的是监督式的方法去训练。<br>ptrnet：比如求第一个位置，就和encoder部分的都求一遍权重，和第一个关系最大，就输出1，没有词汇表，输出从输入里面选</p>
<p><img src="/2025/01/04/mixed-ranking/images/seq2slate.png" alt="alt text"></p>
<h3 id="GRN"><a href="#GRN" class="headerlink" title="GRN"></a><a target="_blank" rel="noopener" href="https://www.notion.so/GRN-17b9114a541680198a4fc3d7b5414f0d">GRN</a></h3><h2 id="Two-Stage"><a href="#Two-Stage" class="headerlink" title="Two-Stage"></a>Two-Stage</h2><h3 id="SetToSeq"><a href="#SetToSeq" class="headerlink" title="SetToSeq"></a>SetToSeq</h3><h3 id="PIER"><a href="#PIER" class="headerlink" title="PIER"></a><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/NUpGoNM1P5Z5JZ0QPj3D5w">PIER</a></h3><p><img src="/2025/01/04/mixed-ranking/images/PIER.png" alt="alt text"></p>
<h2 id="RL"><a href="#RL" class="headerlink" title="RL"></a>RL</h2><p>从action space的角度出发，基于RL的混排模型可以分为以下两类:</p>
<h3 id="离散action-space"><a href="#离散action-space" class="headerlink" title="离散action space"></a>离散action space</h3><ul>
<li>以不同类型结果的mix pattern为action space</li>
<li>代表工作: <strong>Cross DQN: Cross Deep Q Network for Ads Allocation in Feed</strong></li>
<li>实现方式:<ul>
<li>每种内容的结果经过精排后形成内部有序队列，如:<ul>
<li>A&#x3D;(a1,a2,a3,a4)</li>
<li>B&#x3D;(b1,b2,b3,b4) </li>
<li>C&#x3D;(c1,c2,c3,c4)</li>
</ul>
</li>
<li>RL model的action space是不同类型内容的混排pattern</li>
<li>每种混排结果对应一种结果类型的mix pattern</li>
<li>示例:mix pattern &#x3D; AABCB，输出mix list&#x3D;a1-a2-b1-c1-b2</li>
<li>action space size &#x3D; x^N (x为结果类型数,N为混排list长度)</li>
<li>state包含user side info和当前各队列候选list等context</li>
<li>特例:某些场景需要决定是否在首位透出广告&#x2F;直播,此时action space简化为透出&#x2F;不透出</li>
</ul>
</li>
</ul>
<h3 id="连续action-space"><a href="#连续action-space" class="headerlink" title="连续action space"></a>连续action space</h3><ul>
<li>以多目标融合公式的加权系数作为action space</li>
<li>代表工作: <strong>Multi-Task Fusion via Reinforcement Learning for Long-Term User Satisfaction in Recommender Systems</strong></li>
<li>实现方式:<ul>
<li>精排后每种内容的混排分由统一的多目标融合公式给出</li>
<li>示例:mix_score &#x3D; w1 * ctr + w2 * wtr + w3 * ltr</li>
<li>RL学习个性化权重wi</li>
<li>采用non-Deterministic Policy Gradient时,w由学习的均值mu和方差sigma决定</li>
<li>state包含user side和context信息</li>
</ul>
</li>
</ul>
<p>三、方案比较</p>
<ol>
<li><p>A方案(离散action space)特点:</p>
<ul>
<li>一般采用double-DQN等模型</li>
<li>action space不宜过大(需要对离散空间取max)</li>
<li>便于控制不同类型结果比例</li>
<li>适合流量调控(根据mix pattern修正reward)</li>
</ul>
</li>
<li><p>B方案(连续action space)特点:</p>
<ul>
<li>基于多目标融合公式进行混排</li>
<li>RL用于动态调整系数,实现个性化</li>
<li>需要处理不同内容pxtr的量纲不一致问题</li>
<li>non-Deterministic Policy的方差可提供探索能力</li>
</ul>
</li>
</ol>
<h3 id="京东"><a href="#京东" class="headerlink" title="京东"></a>京东</h3><p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/MtIe1fZUdK94buLR5Sm64Q">refer</a><br>基于强化学习的序列优化<br><img src="/2025/01/04/mixed-ranking/images/image-8.png" alt="alt text"></p>
<p><img src="/2025/01/04/mixed-ranking/images/image-9.png" alt="alt text"><br>序列生成和评估模型结构包含两个主要部分:</p>
<ol>
<li>序列评估模型</li>
</ol>
<ul>
<li>底层进行特征抽取,使用Point DNN结构对每个item单独抽取特征</li>
<li>Point DNN将稀疏的embedding转化为dense feature,得到item的特征向量</li>
<li>在序列评估模型中,将序列对应的向量抽取组成序列</li>
<li>对序列进行attention操作,突出最相关的特征</li>
<li>输出每个item的预估点击率,与出价、多样性等业务指标融合得到最终得分</li>
</ul>
<ol start="2">
<li>序列生成模型</li>
</ol>
<ul>
<li>输入:将整个候选集合作为生成模型的输入</li>
<li>特征处理:<ul>
<li>对候选集中所有item特征做max pooling得到候选集合的特征向量</li>
<li>将集合特征向量与每个item的特征向量拼接得到新特征</li>
<li>新特征经过多层DNN处理得到概率矩阵</li>
</ul>
</li>
</ul>
<p>如图举例，假设一共有五个item，序列长度是四。如上图左上的表格，按行来看表示的是每一个item出现在当前这个位置的概率，按列来看表示的是item出现在不同位置的概率。模型训练使用2D softmax的交叉熵loss。如果一个item在候选集里被选中了，并且是出现在第一个位置，它的第一个位置的label就是1。如图，SKU1在第一个位置label是1，SKU2在第三个位置label是1。训练完成的模型在线上预测过程中预测采样频率，用一个受控的temperature参数来控制这个采样频率。按照这个表去生成序列，逐个位置去采样多次生成多个序列。举例来说，生成第一个位置需要的SKU，类似扔一个骰子，如果小于0.9，SKU1被选中，如果是0.9到1，SKU2被选中。第二个位置去除第一个位置已经出现过的SKU，进行重新归一化，再采样一次，这样可以生成多个候选序列。再把这些候选序列与启发式的或者随机生成的序列融合起来，变成一个序列的候选集，统一交给序列的评估模型去评估，选出一个最好的序列。</p>
<h3 id="美团"><a href="#美团" class="headerlink" title="美团"></a>美团</h3><h4 id="（页面级序列建模）Deep-Page-Level-Interest-Network-in-Reinforcement-Learning-for-Ads-Allocation"><a href="#（页面级序列建模）Deep-Page-Level-Interest-Network-in-Reinforcement-Learning-for-Ads-Allocation" class="headerlink" title="（页面级序列建模）Deep Page-Level Interest Network in Reinforcement Learning for Ads Allocation."></a>（页面级序列建模）Deep Page-Level Interest Network in Reinforcement Learning for Ads Allocation.</h4><p>Accepted by SIGIR2022<br><img src="/2025/01/04/mixed-ranking/images/image-5.png" alt="alt text"></p>
<h4 id="（多通道建模）Cross-DQN-Cross-Deep-Q-Network-for-Ads-Allocation-in-Feed"><a href="#（多通道建模）Cross-DQN-Cross-Deep-Q-Network-for-Ads-Allocation-in-Feed" class="headerlink" title="（多通道建模）Cross DQN: Cross Deep Q Network for Ads Allocation in Feed"></a>（多通道建模）Cross DQN: Cross Deep Q Network for Ads Allocation in Feed</h4><p><img src="/2025/01/04/mixed-ranking/images/image-6.png" alt="alt text"></p>
<h3 id="Reinforcement-Learning-to-Rank-with-Pairwise-Policy-Gradient"><a href="#Reinforcement-Learning-to-Rank-with-Pairwise-Policy-Gradient" class="headerlink" title="Reinforcement Learning to Rank with Pairwise Policy Gradient"></a>Reinforcement Learning to Rank with Pairwise Policy Gradient</h3><p>这篇论文关注的是信息检索（IR）中的文档排序模型的强化学习（RL）。其中一个分支的方法是将排序过程形式化为马尔可夫决策过程（MDP），并通过策略梯度来确定模型参数。尽管这些方法已经取得了一些初步的成功，但它们仍未完全实现其潜力。现有的策略梯度方法直接使用采样文档列表的绝对性能分数（回报）在其梯度估计中，这可能导致两个限制：1) 无法反映同一查询内文档之间的相对优劣，而这通常与信息检索排序的本质更接近；2) 产生高方差的梯度估计，导致学习速度慢和排序准确性低。为了解决这些问题，本文提出了一种新的策略梯度算法，即成对策略梯度（Pairwise Policy Gradient, PPG），该算法使用同一查询下采样的两个文档列表进行成对比较来确定梯度。PPG算法重复采样文档列表对，通过成对比较估计梯度，并最终更新模型参数。理论分析表明，PPG能够做出无偏且低方差的梯度估计。实验结果也证明了在搜索结果多样化和文本检索方面，相比现有最先进基线方法，PPG有显著的性能提升。</p>
<h2 id="个性化"><a href="#个性化" class="headerlink" title="个性化"></a>个性化</h2><h3 id="Multi-Level-Interaction-Reranking-with-User-Behavior-History"><a href="#Multi-Level-Interaction-Reranking-with-User-Behavior-History" class="headerlink" title="Multi-Level Interaction Reranking with User Behavior History"></a><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/F0tl3GNlUeFqZsN5hzp8Lg">Multi-Level Interaction Reranking with User Behavior History</a></h3><p>该研究关注的是多阶段推荐系统（MRS）的最终阶段——重排序（reranking），其直接关系到用户的体验和满意度，在MRS中扮演着关键角色。尽管现有工作已经取得了一定的进步，但仍有三个问题尚未得到解决：</p>
<ol>
<li>用户历史行为中的偏好信息未被充分利用：用户的历史行为包含丰富的偏好信息，例如用户的长期和短期兴趣，但在重排序过程中并未被充分挖掘。以往的工作通常将历史记录中的项目视为同等重要，忽略了历史与候选项目之间的动态交互。</li>
<li>现有的重排序模型主要关注项目级别的交互，而忽略了特征级别的细粒度交互：这导致了对项目之间细微影响的捕捉不足，从而影响了重排序的效果。</li>
<li>在重排序前对初始有序列表进行评分可能导致过早评分问题：这种做法可能会产生次优的重排序性能，因为评分是在固定顺序下进行的，未能充分考虑到不同排列可能带来的不同效果。</li>
</ol>
<p>为了解决上述问题，本文提出了一种名为多层次交互重排序（Multi-level Interaction Reranking, MIR）的框架。MIR结合了低级别的跨项目交互和高级别的集到列表交互，其中将待重排序的候选项目视为一个集合，而将用户按时间顺序的行为历史视为一个列表。我们设计了一个新颖的SLAttention结构来建模集到列表的交互，并融合个性化长短期兴趣。此外，为了捕捉项目之间的细粒度影响，我们还引入了特征级别的交互。MIR的设计确保了输入项目的任何排列不会改变输出排名，这一点我们在理论上也进行了证明。</p>
<h2 id="具体模型"><a href="#具体模型" class="headerlink" title="具体模型"></a>具体模型</h2><h3 id="PRM具体模型"><a href="#PRM具体模型" class="headerlink" title="PRM具体模型"></a>PRM具体模型</h3><h3 id="4-2-Input-Layer-输入层"><a href="#4-2-Input-Layer-输入层" class="headerlink" title="4.2 Input Layer (输入层)"></a>4.2 Input Layer (输入层)</h3><ul>
<li><p>**Personalized Vector (PV)**：个性化向量</p>
<ul>
<li>尽管精排队列给出的列表已经有部分个性化结果了，但对于整个用户的个性化结果来说，还不够</li>
<li>本文拼接原始的特征向量X与用户个性化的向量PV(图1b)，从而重排阶段引入用户个性化</li>
</ul>
</li>
<li><p>**Position Embedding (PE)**：位置向量</p>
<ul>
<li>为了利用精排队列中的items的序列信息，本文引入位置编码向量PE(可学习)</li>
<li>使用方式与[X;PV]+PE</li>
<li>在输入向量之后使用FFN进行编码与维度转换，得到图1b中输入层最后的e</li>
</ul>
</li>
</ul>
<h3 id="4-3-Encoding-Layer-编码层"><a href="#4-3-Encoding-Layer-编码层" class="headerlink" title="4.3 Encoding Layer(编码层)"></a>4.3 Encoding Layer(编码层)</h3><ul>
<li>编码层目的是学习items对与额外信息(用户偏好、items初始列表)之间的交互(图1a)</li>
<li>本文使用N层Transformer进行编码，主要考虑到了:<ul>
<li>TRM的并行</li>
<li>self-attention不会依赖item之间的距离等因素</li>
</ul>
</li>
<li>从图1a可以看出，本文使用的Transformer block与原论文基本一致，也是用到了Multi-head Self-Attention，FFN等结构</li>
</ul>
<h3 id="4-4-Output-Layer-输出层"><a href="#4-4-Output-Layer-输出层" class="headerlink" title="4.4 Output Layer(输出层)"></a>4.4 Output Layer(输出层)</h3><ul>
<li>输出层目标是为每个item打出一个重排得分</li>
<li>此处最终使用softmax函数进行输出</li>
<li>输出结果为点击每个item的概率</li>
<li>训练模型时，本文使用点击相关数据完成训练，最终损失函数为交叉熵<br>$$\mathcal{L} &#x3D; \sum_{r\in\mathcal{R}} \ell({y_i, P(y_i|X,PV;\hat{\theta})|i\in\mathcal{S}_r})$$</li>
</ul>
<h3 id="4-5-Personalized-Module-个性化模块"><a href="#4-5-Personalized-Module-个性化模块" class="headerlink" title="4.5 Personalized Module(个性化模块)"></a>4.5 Personalized Module(个性化模块)</h3><ul>
<li>直观来说，可以直接用PRM来端到端学习用户个性化向量PV</li>
<li>然而在重排阶段学习PV，缺少了用户的通用偏好信息</li>
<li>因此本文使用预训练模型生成用户个性化向量(图1c)<ul>
<li>输入为用户的点击序列items(H)，当前item与用户user的信息(性别、年龄、购买力等)</li>
<li>训练数据仍然使用点击数据</li>
<li>损失函数为二分类交叉熵</li>
<li>最终取sigmoid之前层网络的输出结果作为用户个性化向量PV</li>
</ul>
</li>
<li>由于是CTR任务，作者也建议使用FM、FFM、DeepFM、DCN、FFN、PNN等用来学习PV</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://2010727302.github.io/2024/12/24/Budget-Dynamic/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar4.jpg">
      <meta itemprop="name" content="Yuhan Wang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="一个田螺突然就">
      <meta itemprop="description" content="Yuhan Wang's Blog">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 一个田螺突然就">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/12/24/Budget-Dynamic/" class="post-title-link" itemprop="url">Budget&Dynamic</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-12-24 16:15:06" itemprop="dateCreated datePublished" datetime="2024-12-24T16:15:06+08:00">2024-12-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-12-31 18:49:33" itemprop="dateModified" datetime="2024-12-31T18:49:33+08:00">2024-12-31</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/research/" itemprop="url" rel="index"><span itemprop="name">research</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="An-efficient-multi-item-dynamic-auction-with-budget-constrained-bidders"><a href="#An-efficient-multi-item-dynamic-auction-with-budget-constrained-bidders" class="headerlink" title="An efficient multi-item dynamic auction with budget constrained bidders"></a>An efficient multi-item dynamic auction with budget constrained bidders</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>拍卖人出售多个不可分割物品给潜在投标人，投标人有估值但可能受预算约束，瓦尔拉斯均衡可能不存在。本文提出新颖动态拍卖，能找到核心分配，其包含物品分配与支持价格向量，可实现帕累托效率且对联盟偏离威胁有鲁棒性，拍卖中价格过高时可降低。</p>
<h3 id="要点"><a href="#要点" class="headerlink" title="要点"></a>要点</h3><ol>
<li><strong>模型构建</strong><ul>
<li>包含卖家和多个潜在投标人，卖家有不可分割物品，投标人对物品有估值和预算，且预算为私有信息，定义了相关概念如价格向量、分配、瓦尔拉斯均衡等，还阐述了核心和严格核心概念及性质。</li>
</ul>
</li>
<li><strong>动态拍卖机制</strong><ul>
<li>投标人提交出价，拍卖人据出价选分配和价格，投标人再更新出价，重复至无人更新。该拍卖与其他拍卖相比有独特之处，如价格调整灵活、允许降出价等。</li>
<li>证明了拍卖在有限轮终止，且终止时结果为核心分配，在无预算约束时为严格核心分配且分配完全有效。</li>
</ul>
</li>
</ol>
<h3 id="实验方法"><a href="#实验方法" class="headerlink" title="实验方法"></a>实验方法</h3><p>通过理论分析和举例说明的方式，如在阐述模型时举了多个例子说明不同情况下的市场均衡和核心分配情况，在证明拍卖相关性质时运用了数学推导和逻辑推理。</p>
<h2 id="AuctionNet-A-Novel-Benchmark-for-Decision-Making-in-Large-Scale-Games"><a href="#AuctionNet-A-Novel-Benchmark-for-Decision-Making-in-Large-Scale-Games" class="headerlink" title="AuctionNet: A Novel Benchmark for Decision-Making in Large-Scale Games"></a>AuctionNet: A Novel Benchmark for Decision-Making in Large-Scale Games</h2><ol>
<li><strong>摘要</strong>：决策制定在大规模游戏中是人工智能的重要研究领域，本文提出AuctionNet基准，用于大规模广告拍卖中的出价决策。它由广告拍卖环境、预生成数据集和基线出价决策算法性能评估三部分组成。环境通过多个模块交互复制真实拍卖的完整性和复杂性，数据集包含众多代理竞争轨迹，还评估了多种基线算法性能，该基准已应用于NeurIPS 2024竞赛。</li>
<li><strong>要点</strong><ul>
<li><strong>决策问题</strong>：关注广告拍卖中的自动出价问题，用部分可观测随机博弈（POSG）公式化问题，优化目标是在预算约束下最大化价值。</li>
<li><strong>广告拍卖环境</strong>：包含广告机会生成、出价和拍卖等模块。广告机会生成模块用深度生成模型生成数据，降低与现实差距并避免敏感数据暴露；出价模块模拟广告主竞争，实现多种算法；拍卖模块基于经典GSP拍卖，支持多种规则和多广告位特性。</li>
<li><strong>预生成数据集</strong>：基于环境生成，包含大量广告剧集、机会和记录，可用于深入了解拍卖生态，分析印象值随时间变化及不同类别关系。</li>
<li><strong>基线算法评估</strong>：评估了线性规划、强化学习和生成模型等基线算法性能，如Online LP表现较好，IQL和BC等有优化潜力。</li>
</ul>
</li>
<li><strong>实验方法</strong><ul>
<li><strong>环境构建与交互</strong>：将广告机会按时间划分决策步骤，代理依次出价，环境提供最终性能，通过多个模块交互实现真实拍卖模拟。</li>
<li><strong>数据集生成与分析</strong>：使用深度生成模型生成数据，通过PCA可视化、分析价值分布和字段连接等方式验证生成数据与真实数据的相似性，生成的数据集用于分析不同类别印象值变化及关系。</li>
<li><strong>算法评估</strong>：在基本任务和目标CPA任务中评估基线算法，比较不同算法性能，未对方法针对自动出价任务进行特殊优化。</li>
</ul>
</li>
</ol>
<h2 id="Reinforcement-Mechanism-Design-With-Applications-to-Dynamic-Pricing-in-Sponsored-Search-Auctions"><a href="#Reinforcement-Mechanism-Design-With-Applications-to-Dynamic-Pricing-in-Sponsored-Search-Auctions" class="headerlink" title="Reinforcement Mechanism Design: With Applications to Dynamic Pricing in Sponsored Search Auctions"></a>Reinforcement Mechanism Design: With Applications to Dynamic Pricing in Sponsored Search Auctions</h2><h3 id="摘要-1"><a href="#摘要-1" class="headerlink" title="摘要"></a>摘要</h3><p>在赞助搜索中，标准机制是广义第二价格（GSP）拍卖，但存在非收入最优问题。本文研究个体和组织互动的社会系统，以赞助搜索拍卖为背景，结合机制设计和人工智能工具解决搜索引擎动态定价问题。通过训练买家行为模型，将动态定价问题建模为马尔可夫决策过程（MDP），应用强化学习算法优化储备价格，实验表明该模型优于多种静态和动态优化策略。</p>
<ol>
<li><strong>研究背景</strong><ul>
<li><strong>赞助搜索拍卖现状</strong>：在线销售广告是搜索引擎公司的盈利模式，如谷歌和百度。用户搜索时，搜索引擎展示广告，广告商竞价竞争位置，按点击付费。常见的广义第二价格（GSP）拍卖机制存在收入非最优问题，且多数收入优化理论基于竞标者理性行为假设，但实际中该假设常不成立。</li>
<li><strong>相关研究不足</strong>：新兴研究关注竞标者使用学习算法的情况，但多数模型未详细描述竞标者实际行为，难以捕捉异质竞标者群体的不同理性水平。</li>
</ul>
</li>
<li><strong>研究方法</strong><ul>
<li><strong>强化机制设计</strong>：提出混合方法，结合机制设计理论和机器学习技术。先依据机制设计理论用参数描述机制，再用优化算法寻找最优参数；同时用机器学习算法构建精确的竞标者行为模型，将机制参数作为输入，考虑机器学习和战略竞标者行为。</li>
<li><strong>构建竞标者行为模型</strong><ul>
<li><strong>RNN模型</strong>：基于循环神经网络（RNN）构建，输入包括连续m天的关键绩效指标（KPI）、竞标者的出价分布及日期相关特征。RNN输出经全连接层和softmax激活函数转换为有效概率分布。为简化出价分布表示，将其离散为100维向量。KPI统计数据取对数并用tile - coding编码，以捕捉竞标者对相对变化的关注。同时包含公共特征集，如日期相关特征，因多数广告商有季节性广告活动。</li>
<li><strong>数学表述为马尔可夫模型</strong>：采用时间齐次马尔可夫模型解释RNN - 基于竞标者行为模型，即竞标者下一时间步的出价分布是前m个时间步出价分布和KPI的函数，该模型符合文献及百度实际观察。</li>
</ul>
</li>
<li><strong>强化机制设计框架</strong><ul>
<li><strong>问题表述为MDP</strong>：将动态机制设计问题表述为马尔可夫决策过程（MDP），其中竞标者出价分布为状态，储备价格为行动。目标是选择一系列储备价格配置文件以最大化贴现收入总和。</li>
<li><strong>优化算法</strong>：虽存在最优储备定价方案，但精确计算成本高。通过限制关注少数主要竞标者的关键词及仅探索当前储备价格小邻域内的行动来降低计算复杂度，并采用蒙特卡洛树搜索（MCTS）算法，通过限制搜索深度和搜索轨迹数量有效控制计算复杂性。</li>
</ul>
</li>
</ul>
</li>
<li><strong>实验设计与结果</strong><ul>
<li><strong>实验设置</strong>：选择400个具有特定属性（日查询量大且稳定、大部分收入由最多3个竞标者贡献）的关键词，提取8个月的竞价数据（超70TB）。对每个关键词关注3个主要竞标者，为其构建LSTM网络，设置时间步为1天，用90%数据训练，10%测试，以平均交叉熵为性能指标，用ADAM优化器优化。MCTS算法中探索储备价格为当前储备价格的0.95、1.0和1.05倍，设置相关参数如λ &#x3D; 0.8、搜索深度为5等。</li>
<li><strong>结果分析</strong><ul>
<li><strong>策略比较</strong>：动态策略（MCTS）优于所有静态策略（如STATIC OPT、BAIDU、STATIC 50）及动态策略（GREEDY和POLICY GRAD）。BAIDU曲线快速收敛；STATIC OPT曲线先升后降；之前百度在线实验表明STATIC OPT短期内收入高但长期下降，与模拟结果相符，证明竞标者行为模型准确性。激进定价方案短期内收入高但长期下降，因竞标者对储备价格变化作出反应。GREEDY和POLICY GRAD算法表现良好，虽稍逊于MCTS但更简单、计算成本低，表明竞标者可能不太具战略性。</li>
<li><strong>储备价格更新频率影响</strong>：MCTS算法中，更新储备价格频率越低（Δt越大），收入越高且收敛越快。GREEDY算法性能与Δt &#x3D; 3时的MCTS算法几乎相同。</li>
</ul>
</li>
</ul>
</li>
<li><strong>研究结论</strong><ul>
<li>提出结合机制设计和人工智能技术的动态定价框架，不依赖多数理论分析中的不现实假设，采用数据驱动方法解决理论市场设计问题。</li>
<li>框架包含竞标者行为模型（RNN）和优化算法（MCTS），迭代寻找最优机制参数，通过模拟拍卖估计未来目标。</li>
<li>在中国主要搜索引擎百度的真实竞价数据实验中，该框架显著提高收入，已被百度采用并证明能增加收入。</li>
</ul>
</li>
</ol>
<h2 id="A-dynamic-auction-for-multi-object-procurement-under-a-hard-budget-constraint"><a href="#A-dynamic-auction-for-multi-object-procurement-under-a-hard-budget-constraint" class="headerlink" title="A dynamic auction for multi-object procurement under a hard budget constraint"></a>A dynamic auction for multi-object procurement under a hard budget constraint</h2><h3 id="摘要-2"><a href="#摘要-2" class="headerlink" title="摘要"></a>摘要</h3><p>本论文重新审视了政府机构分配研发补贴的问题。通常，申请人的财务约束属于私人信息。已有文献建议采用拍卖方式，以减少信息租金，从而提高稀缺公共资金的分配效率。针对这一采购问题，我们提出了一种新的开放式时钟拍卖。这种拍卖在战略上较为简单，因为它在占优策略中体现了说实话的特性，并且在遵守预算约束的同时满足事后理性。我们通过蒙特卡洛模拟对该拍卖进行了测试，并讨论了其适用性和局限性。此外，我们还强调了与计算机科学最新进展的联系。</p>
<ol>
<li><strong>研究背景</strong><ul>
<li><strong>创新与市场失灵</strong>：创新存在市场失灵特性，如不可分割性、不可占有性和不确定性，私人企业研发投资常非社会最优，政府采用多种政策工具干预，其中直接补贴私人研发尤为重要，如美国小企业创新研究计划（SBIR）。</li>
<li><strong>补贴效果与问题</strong>：公共研发资金对社会有益，有直接资助和“光晕”或信号效应等好处，但现有补贴分配实践存在问题，如未充分考虑项目性价比，可能导致资金浪费，同时政府政策可能受游说或政治压力扭曲。</li>
</ul>
</li>
<li><strong>模型构建</strong><ul>
<li><strong>参与者与物品</strong>：政府机构为“买家”，申请人为“卖家”，卖家有不可分割物品（研究提案），有私知保留价格(\theta_{i})，提交财务出价(b_{i})，买家有固定预算(B)。</li>
<li><strong>质量等级与权重</strong>：为评估买家效用，给每个申请人项目设定质量等级及相对权重（如A项目权重1，B项目0.7等），资金决策基于这些等级，实际质量在决策时不确定。</li>
<li><strong>买家效用与目标</strong>：买家目标是在预算约束下最大化采购物品总质量，效用函数为(u_{buyer}(\mathcal{A})&#x3D;\sum_{j \in \mathcal{A}} w_{j}&#x3D;\sum_{i \in \mathcal{I}} q_{i} w_{i}, q_{i} \in{0,1})，完全信息下的最优分配是解决相关二进制背包问题。</li>
</ul>
</li>
<li><strong>拍卖机制</strong><ul>
<li><strong>初始设置</strong>：申请人给定财务起始出价(\bar{b}<em>{i})（如当前补贴或匹配赠款），起始出价除以质量得到初始价格质量比(\bar{r}</em>{i})。</li>
<li><strong>拍卖过程</strong>：采用开放递减时钟拍卖，时钟从最高初始价格质量比开始倒计时，投标人可随时退出且不能再进入。只要活跃投标人财务出价总和超预算，倒计时继续，直到预算能容纳剩余活跃出价或正好耗尽预算时拍卖结束。</li>
<li><strong>支付与结果</strong>：输家保留物品无支付，赢家根据拍卖结束方式获得支付（若因退出结束，支付由退出者最终价格质量比决定；若因耗尽预算结束，支付用完预算）。该机制中，说实话是占优策略，满足预算约束且事后个体理性。</li>
</ul>
</li>
<li><strong>模拟分析</strong><ul>
<li><strong>模拟设置</strong>：通过蒙特卡洛模拟，假设卖家采用占优策略均衡，对模型参数做多种假设，随机抽取储备价格和信息租金，比较动态拍卖（DA）与最优分配（FB）和现状分配（SQ）。</li>
<li><strong>模拟结果</strong><ul>
<li><strong>信息租金影响</strong>：DA旨在减少信息租金，在无信息租金时，DA近似FB且优于SQ；信息租金越大，DA相对SQ优势越明显。</li>
<li><strong>福利权重影响</strong>：B和C项目福利权重越高，SQ分配误差越大，因SQ过于重视A项目，而DA分配规则能适应福利权重变化。</li>
<li><strong>预算规模影响</strong>：预算增加时，SQ和DA性能都提升，但SQ对预算变化更敏感。</li>
<li><strong>储备价格分布影响</strong>：多数情况下，储备价格分布假设对SQ和DA相对性能影响不大，DA性能相对稳定，集中在FB的70 - 75%，而SQ在某些情况下性能较差。总体而言，DA对参数变化不太敏感，跟踪误差主要源于信息租金，SQ则因基本分配误差对假设变化敏感。</li>
</ul>
</li>
</ul>
</li>
<li><strong>讨论与结论</strong><ul>
<li><strong>适用性与局限性</strong>：论文基于前人对研发补贴分配的研究，改进拍卖设计简化战略问题，提供稳健预测。假设虽合理但现实中可能被违反，如引入拍卖可能改变申请人行为，导致项目性质、成本超支和作弊风险变化；模型假设项目为完美替代品可能扭曲分配，但偏离该假设会使评估和拍卖难以实施；改变补贴分配方式可能影响高质量申请人数量，但平均质量下降可能仍意味着福利改进；理论上更多参与者应改善拍卖分配，但实践中需平衡项目数量与政策目标及项目启动延迟问题；光环或认证效应使拍卖更理想，但可能降低补贴项目平均质量。</li>
<li><strong>实施与建议</strong>：实施拍卖需程序管理选择质量等级和福利权重，申请人准备提案并确定储备价格，拍卖实施相对简单且能增加资金决策透明度。使用拍卖的利弊因具体情况而异，需在现实中测试并评估效果，机制适用性取决于创新类型、目标群体和政策目标等因素，理论结果也可能适用于研发资金以外场景。</li>
</ul>
</li>
</ol>
<h2 id="Spending-Programmed-Bidding-Privacy-friendly-Bid-Optimization-with-ROI-Constraint-in-Online-Advertising"><a href="#Spending-Programmed-Bidding-Privacy-friendly-Bid-Optimization-with-ROI-Constraint-in-Online-Advertising" class="headerlink" title="Spending Programmed Bidding: Privacy-friendly Bid Optimization with ROI Constraint in Online Advertising"></a>Spending Programmed Bidding: Privacy-friendly Bid Optimization with ROI Constraint in Online Advertising</h2><h3 id="摘要-3"><a href="#摘要-3" class="headerlink" title="摘要"></a>摘要</h3><p>  隐私政策使得实时且精确的用户数据无法追踪，这扰乱了价值数十亿美元的在线广告市场，给在线广告行业中受投资回报率（ROI）约束的产品优化带来了重大挑战。隐私保护策略，包括事件聚合和报告延迟，阻碍了对详细和即时反馈数据的获取，从而使传统的身份揭示归因技术无法发挥作用。在本文中，我们引入了一种新颖的支出程序化出价（SPB）框架来应对这些挑战。SPB是一个两阶段框架，将长期投放支出规划（宏观阶段）和短期出价执行（微观阶段）分开。宏观阶段对目标ROI进行建模以实现最大效用并得出预期支出，而微观阶段则在给定预期支出的情况下优化出价价格。我们进一步将我们的框架扩展到跨渠道场景，在该场景中，代理在受隐私约束和身份揭示归因渠道中进行出价。我们发现，当存在受隐私约束的渠道时，SPB在离线数据集和大型广告平台的在线实验中均优于最先进的出价方法。<br>  “Spending Programmed Bidding: Privacy-friendly Bid Optimization with ROI Constraint in Online Advertising”由Yumin Su、Min Xiang等人撰写，提出了一种创新的在线广告出价框架Spending Programmed Bidding (SPB)，以解决隐私保护下ROI约束的出价优化问题。</p>
<ol>
<li><strong>研究背景</strong><ul>
<li><strong>隐私政策影响广告效果</strong>：隐私政策使实时精准用户数据难以追踪，影响在线广告的ROI优化。如苹果的PCM和SKAN策略虽保护隐私，但存在事件聚合和报告延迟问题，影响广告投放和效果评估。</li>
<li><strong>现有方法的局限性</strong>：传统身份揭示方法受隐私约束，在解决报告延迟、依赖实时数据等问题上存在局限，如CVR预测模型、PID、MPC和RL等方法在隐私场景中效果不佳。</li>
</ul>
</li>
<li><strong>研究方法</strong><ul>
<li><strong>问题定义与数学表示</strong>：基于在线随机背包问题定义，目标是在ROI和花费约束下最大化GMV，给出了相关数学公式和符号定义。</li>
<li><strong>隐私场景挑战</strong>：隐私政策导致拍卖中(c_i)和(wp_i)获取困难，使问题面临粗粒度、滞后性和随机性挑战，影响传统优化方法和实时反馈控制方法的适用性。</li>
<li><strong>SPB框架</strong><ul>
<li><strong>两阶段分解</strong>：将在线出价过程分为宏观和微观阶段。宏观阶段根据长期数据规划最优花费(S^{(opt)})，微观阶段基于(S^{(opt)})生成实时出价价格，有效应对隐私场景挑战。</li>
<li><strong>阈值算法（THRESHOLD）</strong>：一种贪婪算法，在特定条件下可近似解决问题，通过确定阈值(R_{thr})计算最优出价，SPB算法对其改进以适应隐私场景。</li>
<li><strong>宏观花费规划</strong>：通过探索最优GMV和最优ROI的关系，构建函数关系计算最优花费，利用长期累积数据应对隐私挑战，通过多日数据聚合和拟合确定函数参数。</li>
<li><strong>微观出价优化</strong>：在宏观确定总体最优花费基础上，通过预算分配获得短期最优花费，利用IMPC方法构建(R_{thr})和花费(P_S)的线性插值模型计算最优出价，具有无累积误差、无需先验函数分布、稳健便携等优点。</li>
<li><strong>多渠道推广</strong>：将SPB扩展到多渠道场景，宏观部分联合求解各渠道最优花费，微观部分独立应用IMPC算法计算出价，通过定理4确定各渠道(R_{thr})相等时整体(P_G)最大。</li>
</ul>
</li>
</ul>
</li>
<li><strong>实验验证</strong><ul>
<li><strong>实验设置</strong>：使用TikTok广告平台工业数据集和模拟隐私数据集，定义预算拆分实验机制，介绍SPB方法设置。</li>
<li><strong>性能评估指标</strong>：根据ROI和花费利用率将广告活动分组，通过计算GMV和花费评估出价方法性能。</li>
<li><strong>对比出价方法</strong>：对比BidCap、MPC和SPB三种出价方法。</li>
<li><strong>实验结果</strong><ul>
<li><strong>在线实验</strong>：SPB在Accomplish组提高GMV和收入，在Violation组降低GMV和收入；在隐私约束场景表现良好，尤其在SKAN归因活动中；对ROI波动容忍度降低时，Violation组GMV比例增加较小，GMV分布更倾向于(R_{res}&#x2F;R_{target}&gt;1)。</li>
<li><strong>离线实验</strong>：SPB在Accomplish组增强GMV，在Violation组降低GMV；在不同延迟下，Accomplish组比例高且随延迟增加优势更明显，Violation组GMV比例增加缓慢；在离线环境中，GMV分布更集中于(R_{res}&#x2F;R_{target}&#x3D;1)，能产生更多(R_{res}&#x2F;R_{target}≥1.0)的GMV。</li>
</ul>
</li>
</ul>
</li>
<li><strong>研究结论</strong><ul>
<li>提出的SPB框架有效解决隐私保护下ROI约束的出价优化问题，在离线和在线实验中表现优于现有方法。</li>
<li>未来将探索更隐私敏感的广告市场平衡。</li>
</ul>
</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://2010727302.github.io/2024/10/24/sync/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar4.jpg">
      <meta itemprop="name" content="Yuhan Wang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="一个田螺突然就">
      <meta itemprop="description" content="Yuhan Wang's Blog">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 一个田螺突然就">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/10/24/sync/" class="post-title-link" itemprop="url">多进程</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2024-10-24 17:43:00 / 修改时间：15:24:20" itemprop="dateCreated datePublished" datetime="2024-10-24T17:43:00+08:00">2024-10-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Interview/" itemprop="url" rel="index"><span itemprop="name">Interview</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          这里有东西被加密了，需要输入密码查看哦。
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2024/10/24/sync/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://2010727302.github.io/2024/10/10/KDD2024-adv/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar4.jpg">
      <meta itemprop="name" content="Yuhan Wang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="一个田螺突然就">
      <meta itemprop="description" content="Yuhan Wang's Blog">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 一个田螺突然就">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/10/10/KDD2024-adv/" class="post-title-link" itemprop="url">KDD2024 adv</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-10-10 20:06:19" itemprop="dateCreated datePublished" datetime="2024-10-10T20:06:19+08:00">2024-10-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-01-04 14:11:47" itemprop="dateModified" datetime="2025-01-04T14:11:47+08:00">2025-01-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/research/" itemprop="url" rel="index"><span itemprop="name">research</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="KDD-2024-工业界搜广推（广告）工作整理"><a href="#KDD-2024-工业界搜广推（广告）工作整理" class="headerlink" title="KDD 2024 工业界搜广推（广告）工作整理"></a>KDD 2024 工业界搜广推（广告）工作整理</h1><p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/jSRiHyg0yRGaRzFDpIl81Q">参考</a></p>
<h1 id="Alibaba"><a href="#Alibaba" class="headerlink" title="Alibaba"></a><strong>Alibaba</strong></h1><p><strong>生成式出价 |</strong> <strong>Generative Auto-bidding via Conditional Diffusion Modeling</strong></p>
<p>利用条件扩散模型进行自动出价，提高在线广告的效率。</p>
<p>Jiayan Guo (Peking University, Alibaba Group); Yusen Huo (Alibaba Group); Zhilin Zhang (Alibaba Group); Tianyu Wang (Alibaba Group); Chuan Yu (Alibaba Group); Jian Xu (Alibaba Group); Bo Zheng (Alibaba Group); Yan Zhang (Peking University)</p>
<p><strong>因果推断 | CURLS: Causal Rule Learning for Subgroups with Significant Treatment Effect</strong></p>
<p>针对具有显著处理效应的子群体的因果规则学习。</p>
<p>Jiehui Zhou (State Key Lab of CAD&amp;CG, Zhejiang University, DAMO Academy, Alibaba Group); Linxiao Yang (DAMO Academy, Alibaba Group); Xingyu Liu (State Key Lab of CAD&amp;CG, Zhejiang University); Xinyue Gu (DAMO Academy, Alibaba Group); Liang Sun (DAMO Academy, Alibaba Group); Wei Chen (State Key Lab of CAD&amp;CG, Zhejiang University)</p>
<p><strong>合约广告 | Bi-Objective Contract Allocation for Guaranteed Delivery Advertising</strong></p>
<p>合约广告的双目标合同分配问题。</p>
<p>an Li (Key Laboratory of System Software (Chinese Academy of Sciences) and State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, School of Computer Science and Technology, University of Chinese Academy of Sciences); Yundu Huang (Alibaba Group); Wuyang Mao (Alibaba Group); Furong Ye (Key Laboratory of System Software (Chinese Academy of Sciences) and State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences); Xiang He (Key Laboratory of System Software (Chinese Academy of Sciences) and State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, School of Computer Science and Technology, University of Chinese Academy of Sciences); Zhonglin Zu (Alibaba Group); Shaowei Cai (Key Laboratory of System Software (Chinese Academy of Sciences) and State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, School of Computer Science and Technology, University of Chinese Academy of Sciences)</p>
<p><strong>拍卖广告 | Truthful Bandit Mechanisms for Repeated Two-stage Ad Auctions</strong></p>
<p>为重复两阶段广告拍卖设计真实性多臂老虎机机制。</p>
<p>Haoming Li (Shanghai Jiaotong University); Yumou Liu (The Chinese University of Hong Kong, Shenzhen); Zhenzhe Zheng (Shanghai Jiao Tong University); Zhilin Zhang (Alibaba Group); Jian Xu (Alibaba Group); Fan Wu (Shanghai Jiao Tong University)</p>
<h1 id="Bytedance"><a href="#Bytedance" class="headerlink" title="Bytedance"></a><strong>Bytedance</strong></h1><p><strong>出价 | Spending Programmed Bidding: Privacy-friendly Bid Optimization with ROI Constraint in Online Advertising</strong></p>
<p>Yumin Su (ByteDance Inc.); Min Xiang (ByteDance Inc.); Yifei Chen (ByteDance Inc.); Yanbiao Li (ByteDance Inc.); Tian Qin (ByteDance Inc.); Hongyi Zhang (ByteDance Inc.); Yasong Li (ByteDance Inc.); Xiaobing Liu (ByteDance Inc.)</p>
<h1 id="Tencent"><a href="#Tencent" class="headerlink" title="Tencent"></a><strong>Tencent</strong></h1><p><strong>排序增强的uplift | Rankability-enhanced Revenue Uplift Modeling Framework for Online Marketing</strong></p>
<p>Bowei He (City University of Hong Kong); Yunpeng Weng (FiT, Tencent); Xing Tang (FiT, Tencent); Ziqiang Cui (City University of Hong Kong); Zexu Sun (Renmin University of China); Liang Chen (FiT, Tencent); Xiuqiang He (FiT, Tencent); Chen Ma (City University of Hong Kong)</p>
<h1 id="Meituan"><a href="#Meituan" class="headerlink" title="Meituan"></a><strong>Meituan</strong></h1><p><strong>拍卖 | Joint Auction in the Online Advertising Market</strong></p>
<p>Zhen Zhang (Gaoling School of Artificial Intelligence, Renmin University of China); Weian Li (School of Software, Shandong University); Yahui Lei (Meituan Inc.); Bingzhe Wang (Gaoling School of Artificial Intelligence, Renmin University of China); Zhicheng Zhang (Gaoling School of Artificial Intelligence, Renmin University of China); Qi Qi (Gaoling School of Artificial Intelligence, Renmin University of China); Qiang Liu (Meituan Inc.); Xingxing Wang (Meituan Inc.)</p>
<p><strong>因果推断 | Decision Focused Causal Learning for Direct Counterfactual Marketing Optimization</strong></p>
<p>Hao Zhou (State Key Laboratory for Novel Software Technology, Nanjing University, Meituan); Rongxiao Huang (State Key Laboratory for Novel Software Technology, Nanjing University); Shaoming Li (Meituan); Guibin Jiang (Meituan); Jiaqi Zheng (State Key Laboratory for Novel Software Technology, Nanjing University); Bing Cheng (Meituan); Wei Lin (Meituan)</p>
<h1 id="Google"><a href="#Google" class="headerlink" title="Google"></a><strong>Google</strong></h1><p><strong>LLM用于拍卖 | Auctions with LLM Summaries</strong></p>
<p>Avinava Dubey (Google Research); Zhe Feng (Google Research); Rahul Kidambi (Google Research); Aranyak Mehta (Google Research); Di Wang (Google Research)</p>
<h1 id="Shopee"><a href="#Shopee" class="headerlink" title="Shopee"></a><strong>Shopee</strong></h1><p><strong>广告校准 | Deep Ensemble Shape Calibration: Multi-Field Post-hoc Calibration in Online Advertising</strong></p>
<p>Shuai Yang (Shopee Discovery Ads); Hao Yang (Shopee Discovery Ads); Zhuang Zou (Shopee Discovery Ads); Linhe Xu (Shopee Discovery Ads); Shuo Yuan (Shopee Discovery Ads); Yifan Zeng (Shopee Discovery Ads)</p>
<h1 id="Meta"><a href="#Meta" class="headerlink" title="Meta"></a><strong>Meta</strong></h1><p><strong>离线强化学习出价 | Offline Reinforcement Learning for Optimizing Production Bidding Policies</strong></p>
<p>Dmytro Korenkevych (AI at Meta); Frank Cheng (AI at Meta); Artsiom Balakir (AI at Meta); Alex Nikulkov (AI at Meta); Lingnan Gao (Meta Platform Inc.); Zhihao Cen (AI at Meta); Zuobing Xu (Meta Platform Inc.); Zheqing Zhu (AI at Meta)</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://2010727302.github.io/2024/09/29/Deep-learning-for-revenue-optimal-auctions-with-budgets/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar4.jpg">
      <meta itemprop="name" content="Yuhan Wang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="一个田螺突然就">
      <meta itemprop="description" content="Yuhan Wang's Blog">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 一个田螺突然就">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/09/29/Deep-learning-for-revenue-optimal-auctions-with-budgets/" class="post-title-link" itemprop="url">Deep learning for revenue-optimal auctions with budgets</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-09-29 21:43:59" itemprop="dateCreated datePublished" datetime="2024-09-29T21:43:59+08:00">2024-09-29</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-10-05 17:46:52" itemprop="dateModified" datetime="2024-10-05T17:46:52+08:00">2024-10-05</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/research/" itemprop="url" rel="index"><span itemprop="name">research</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="1-研究的问题："><a href="#1-研究的问题：" class="headerlink" title="1. 研究的问题："></a>1. 研究的问题：</h3><p>这篇论文研究的问题是如何设计收入最大化的拍卖机制，特别是针对具有私人预算限制的环境中的拍卖。在这种环境下，竞拍者由于财务约束，无法支付超过他们预算的金额。论文探讨了即使在单一物品和两个竞拍者的情况下，带有私人预算约束的最优主导策略激励相容（DSIC）设计也是未知的。作者尝试使用深度学习方法来解决这个问题。</p>
<h3 id="2-研究的对象："><a href="#2-研究的对象：" class="headerlink" title="2. 研究的对象："></a>2. 研究的对象：</h3><p>研究的对象是多物品拍卖环境中的私人预算约束，包括但不限于单一物品拍卖、多物品拍卖、具有附加价值的竞拍者和单位需求竞拍者的拍卖。这些拍卖场景中的竞拍者具有私人价值和预算限制，论文尝试设计出在这些约束下能够最大化预期收益的拍卖规则。</p>
<h3 id="3-使用的技术："><a href="#3-使用的技术：" class="headerlink" title="3. 使用的技术："></a>3. 使用的技术：</h3><p>作者使用了深度学习技术，特别是神经网络来模拟拍卖规则，并使用机器学习进行最优拍卖的自动化设计。具体来说，他们扩展了RegretNet框架，以处理私人预算约束和贝叶斯激励相容性（BIC）。他们还使用了增强拉格朗日方法来解决基于样本的优化问题，并通过Adam优化器来逼近解决内层优化问题。此外，他们还使用了TensorFlow深度学习库进行实验，并采用了增强拉格朗日方法中的拉格朗日乘数更新技术来处理约束条件。</p>
<h3 id="扩展RegretNet的部分"><a href="#扩展RegretNet的部分" class="headerlink" title="扩展RegretNet的部分"></a>扩展RegretNet的部分</h3><p>预算约束（Budget Constraints）：</p>
<p>原始的RegretNet框架没有考虑预算约束。在这篇论文中，作者扩展了框架以包括预算约束，即确保拍卖机制不会让竞拍者支付超过其预算的金额。<br>这是通过在损失函数中加入预算约束（BC）罚分来实现的，以确保每个竞拍者的支付不超过其预算。<br>贝叶斯激励相容性（Bayesian Incentive Compatibility, BIC）：</p>
<p>除了主导策略激励相容性（DSIC），作者还扩展了框架以支持BIC，这是一种在竞拍者类型分布未知的情况下的激励相容性。<br>在BIC拍卖中，竞拍者在报告自己的类型时，说真话是其最优策略，从期望上讲，相对于其他竞拍者的类型。<br>条件激励相容性（Conditional Incentive Compatibility）：</p>
<p>作者还考虑了条件激励相容性，即竞拍者只能低估自己的预算，而不是高估。<br>这需要对RegretNet框架进行进一步的调整，以处理这种单向的激励约束。</p>
<h3 id="公式变化：（3-1）"><a href="#公式变化：（3-1）" class="headerlink" title="公式变化：（3.1）"></a>公式变化：（3.1）</h3><p><img src="/2024/09/29/Deep-learning-for-revenue-optimal-auctions-with-budgets/image1.png" alt="regret"><br>原始RegretNet：<br><img src="/2024/09/29/Deep-learning-for-revenue-optimal-auctions-with-budgets/image2.png" alt="regret"><br>现在的loss function：<br><img src="/2024/09/29/Deep-learning-for-revenue-optimal-auctions-with-budgets/image3.png" alt="regret"><br>原始RegretNet：<br><img src="/2024/09/29/Deep-learning-for-revenue-optimal-auctions-with-budgets/image4.png" alt="regret"><br>其实就是加上考虑了budget和IR，pay要小于budget，收益不能为负<br><img src="/2024/09/29/Deep-learning-for-revenue-optimal-auctions-with-budgets/image8.png" alt="regret"></p>
<h3 id="网络结构变化："><a href="#网络结构变化：" class="headerlink" title="网络结构变化："></a>网络结构变化：</h3><p>本文：<br>Budgeted RegretNet: (a) Allocation rule a and (b) Payment rule p for a setting withm distinct items and n unit-demand buyers.<br><img src="/2024/09/29/Deep-learning-for-revenue-optimal-auctions-with-budgets/image5.png" alt="regret"><br>原始RegretNet：<br><img src="/2024/09/29/Deep-learning-for-revenue-optimal-auctions-with-budgets/image6.png" alt="regret"><br><img src="/2024/09/29/Deep-learning-for-revenue-optimal-auctions-with-budgets/image7.png" alt="regret"><br>其实就是输入的从只有bid变成value（可能不truthful）+budget</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://2010727302.github.io/2024/09/29/Related-Work/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar4.jpg">
      <meta itemprop="name" content="Yuhan Wang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="一个田螺突然就">
      <meta itemprop="description" content="Yuhan Wang's Blog">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 一个田螺突然就">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/09/29/Related-Work/" class="post-title-link" itemprop="url">Related Work</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2024-09-29 17:50:50 / 修改时间：18:01:13" itemprop="dateCreated datePublished" datetime="2024-09-29T17:50:50+08:00">2024-09-29</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>1.研究的问题 2. 研究的对象 3. 使用的技术。</p>
<h1 id="AMD"><a href="#AMD" class="headerlink" title="AMD:"></a>AMD:</h1><h2 id="1-原版"><a href="#1-原版" class="headerlink" title="1.原版"></a>1.原版</h2><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">@misc&#123;conitzer2002complexitymechanismdesign,</span><br><span class="line">      title=&#123;Complexity of Mechanism Design&#125;, </span><br><span class="line">      author=&#123;Vincent Conitzer and Tuomas Sandholm&#125;,</span><br><span class="line">      year=&#123;2002&#125;,</span><br><span class="line">      eprint=&#123;cs/0205075&#125;,</span><br><span class="line">      archivePrefix=&#123;arXiv&#125;,</span><br><span class="line">      primaryClass=&#123;cs.GT&#125;,</span><br><span class="line">      url=&#123;https://arxiv.org/abs/cs/0205075&#125;, </span><br><span class="line">&#125;</span><br><span class="line">@inproceedings&#123;conitzer2004self,</span><br><span class="line">  title=&#123;Self-interested automated mechanism design and implications for optimal combinatorial auctions&#125;,</span><br><span class="line">  author=&#123;Conitzer, Vincent and Sandholm, Tuomas&#125;,</span><br><span class="line">  booktitle=&#123;Proceedings of the 5th ACM Conference on Electronic Commerce&#125;,</span><br><span class="line">  pages=&#123;132--141&#125;,</span><br><span class="line">  year=&#123;2004&#125;</span><br><span class="line">&#125;</span><br><span class="line">@inproceedings&#123;sandholm2003automated,</span><br><span class="line">  title=&#123;Automated mechanism design: A new application area for search algorithms&#125;,</span><br><span class="line">  author=&#123;Sandholm, Tuomas&#125;,</span><br><span class="line">  booktitle=&#123;International Conference on Principles and Practice of Constraint Programming&#125;,</span><br><span class="line">  pages=&#123;19--36&#125;,</span><br><span class="line">  year=&#123;2003&#125;,</span><br><span class="line">  organization=&#123;Springer&#125;</span><br><span class="line">&#125;</span><br><span class="line">@article&#123;sandholm2015automated,</span><br><span class="line">  title=&#123;Automated design of revenue-maximizing combinatorial auctions&#125;,</span><br><span class="line">  author=&#123;Sandholm, Tuomas and Likhodedov, Anton&#125;,</span><br><span class="line">  journal=&#123;Operations Research&#125;,</span><br><span class="line">  volume=&#123;63&#125;,</span><br><span class="line">  number=&#123;5&#125;,</span><br><span class="line">  pages=&#123;1000--1025&#125;,</span><br><span class="line">  year=&#123;2015&#125;,</span><br><span class="line">  publisher=&#123;INFORMS&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>2.本文研究了在线广告平台中的两阶段拍卖架构，该架构用于在低延迟下向用户传递个性化广告。第一阶段从完整的广告池中高效选择一小部分有潜力的广告。第二阶段在子集中进行拍卖以确定展示的广告，使用第二阶段机器学习模型的点击率预测。研究了第一阶段子集选择策略的在线学习过程，并确保在重复的两阶段广告拍卖中具有博弈论属性。提出了一种新的实验设计，即“集群多重随机化设计”（cMRD），它在客户和搜索查询群集级别独立随机化，允许在单一实验中同时衡量定价变化的直接和间接效果。</p>
<figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">@inproceedings&#123;li2024truthful,</span><br><span class="line">  title=&#123;Truthful Bandit Mechanisms for Repeated Two-stage Ad Auctions&#125;,</span><br><span class="line">  author=&#123;Li, Haoming and Liu, Yumou and Zheng, Zhenzhe and Zhang, Zhilin and Xu, Jian and Wu, Fan&#125;,</span><br><span class="line">  booktitle=&#123;Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining&#125;,</span><br><span class="line">  pages=&#123;1565--1575&#125;,</span><br><span class="line">  year=&#123;2024&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="3-regret的一坨"><a href="#3-regret的一坨" class="headerlink" title="3.regret的一坨"></a>3.regret的一坨</h3><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">@article&#123;dutting2024optimal,</span><br><span class="line">  title=&#123;Optimal auctions through deep learning: Advances in differentiable economics&#125;,</span><br><span class="line">  author=&#123;D&#123;<span class="keyword">\&quot;</span>u&#125;tting, Paul and Feng, Zhe and Narasimhan, Harikrishna and Parkes, David C and Ravindranath, Sai Srivatsa&#125;,</span><br><span class="line">  journal=&#123;Journal of the ACM&#125;,</span><br><span class="line">  volume=&#123;71&#125;,</span><br><span class="line">  number=&#123;1&#125;,</span><br><span class="line">  pages=&#123;1--53&#125;,</span><br><span class="line">  year=&#123;2024&#125;,</span><br><span class="line">  publisher=&#123;ACM New York, NY&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>衍生</p>
<figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">@inproceedings&#123;duan2022context,</span><br><span class="line">  title=&#123;A context-integrated transformer-based neural network for auction design&#125;,</span><br><span class="line">  author=&#123;Duan, Zhijian and Tang, Jingwu and Yin, Yutong and Feng, Zhe and Yan, Xiang and Zaheer, Manzil and Deng, Xiaotie&#125;,</span><br><span class="line">  booktitle=&#123;International Conference on Machine Learning&#125;,</span><br><span class="line">  pages=&#123;5609--5626&#125;,</span><br><span class="line">  year=&#123;2022&#125;,</span><br><span class="line">  organization=&#123;PMLR&#125;</span><br><span class="line">&#125;</span><br><span class="line">@article&#123;ivanov2022optimal,</span><br><span class="line">  title=&#123;Optimal-er auctions through attention&#125;,</span><br><span class="line">  author=&#123;Ivanov, Dmitry and Safiulin, Iskander and Filippov, Igor and Balabaeva, Ksenia&#125;,</span><br><span class="line">  journal=&#123;Advances in Neural Information Processing Systems&#125;,</span><br><span class="line">  volume=&#123;35&#125;,</span><br><span class="line">  pages=&#123;34734--34747&#125;,</span><br><span class="line">  year=&#123;2022&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol>
<li><p><strong>“[A Context-Integrated Transformer-Based Neural Network for Auction Design](<a href="https://2010727302.github.io/2024/09/29/A-Context-Integrated-Transformer-Based-Neural-Network-for-Auction-Design/">A Context-Integrated Transformer-Based Neural Network for Auction Design | 一个田螺突然就 (2010727302.github.io)</a>)”</strong> 介绍了一种基于Transformer模型的神经网络，该网络能够整合上下文信息来设计拍卖机制。这种方法能够更好地适应动态变化的市场环境和参与者的多样性。</p>
<p>introduces a neural network based on the Transformer model that integrates contextual information to design auction mechanisms. This approach better adapts to the dynamic market environment and the diversity of participants.</p>
</li>
<li><p><strong>“Optimal-er Auctions through Attention”</strong> 则专注于利用注意力机制来改进拍卖设计。通过关注关键的拍卖参数和参与者特征，该研究提出了一种能够自动调整拍卖规则以适应不同场景的算法。</p>
<p>focuses on improving auction design using attention mechanisms. By focusing on key auction parameters and participant features, the study proposes an algorithm that can automatically adjust auction rules to fit different scenarios.</p>
</li>
</ol>
<h3 id="with-constraints"><a href="#with-constraints" class="headerlink" title="with constraints"></a>with constraints</h3><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">@inproceedings&#123;feng2018deep,</span><br><span class="line">  title=&#123;Deep learning for revenue-optimal auctions with budgets&#125;,</span><br><span class="line">  author=&#123;Feng, Zhe and Narasimhan, Harikrishna and Parkes, David C&#125;,</span><br><span class="line">  booktitle=&#123;Proceedings of the 17th international conference on autonomous agents and multiagent systems&#125;,</span><br><span class="line">  pages=&#123;354--362&#125;,</span><br><span class="line">  year=&#123;2018&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="4-joint"><a href="#4-joint" class="headerlink" title="4.joint"></a>4.joint</h3><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">@inproceedings&#123;zhang2024joint,</span><br><span class="line">  title=&#123;Joint Auction in the Online Advertising Market&#125;,</span><br><span class="line">  author=&#123;Zhang, Zhen and Li, Weian and Lei, Yahui and Wang, Bingzhe and Zhang, Zhicheng and Qi, Qi and Liu, Qiang and Wang, Xingxing&#125;,</span><br><span class="line">  booktitle=&#123;Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining&#125;,</span><br><span class="line">  pages=&#123;4362--4373&#125;,</span><br><span class="line">  year=&#123;2024&#125;</span><br><span class="line">&#125;</span><br><span class="line">@article&#123;aggarwal2024selling,</span><br><span class="line">  title=&#123;Selling joint ads: A regret minimization perspective&#125;,</span><br><span class="line">  author=&#123;Aggarwal, Gagan and Badanidiyuru, Ashwinkumar and D&#123;<span class="keyword">\&quot;</span>u&#125;tting, Paul and Fusco, Federico&#125;,</span><br><span class="line">  journal=&#123;arXiv preprint arXiv:2409.07819&#125;,</span><br><span class="line">  year=&#123;2024&#125;</span><br><span class="line">&#125;</span><br><span class="line">@inproceedings&#123;ma2024joint,</span><br><span class="line">  title=&#123;Joint Bidding in Ad Auctions&#125;,</span><br><span class="line">  author=&#123;Ma, Yuchao and Li, Weian and Zhang, Wanzhi and Lei, Yahui and Zhang, Zhicheng and Qi, Qi and Liu, Qiang and Wang, Xingxing&#125;,</span><br><span class="line">  booktitle=&#123;Annual Conference on Theory and Applications of Models of Computation&#125;,</span><br><span class="line">  pages=&#123;344--354&#125;,</span><br><span class="line">  year=&#123;2024&#125;,</span><br><span class="line">  organization=&#123;Springer&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><a href="https://2010727302.github.io/2024/09/29/Selling-Joint-Ads-A-Regret-Minimization-Perspective/#3-Used-Technology">Selling joint ads: A regret minimization perspective</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://2010727302.github.io/2024/09/29/Selling-Joint-Ads-A-Regret-Minimization-Perspective/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar4.jpg">
      <meta itemprop="name" content="Yuhan Wang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="一个田螺突然就">
      <meta itemprop="description" content="Yuhan Wang's Blog">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 一个田螺突然就">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/09/29/Selling-Joint-Ads-A-Regret-Minimization-Perspective/" class="post-title-link" itemprop="url">Selling Joint Ads: A Regret Minimization Perspective</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-09-29 17:50:08" itemprop="dateCreated datePublished" datetime="2024-09-29T17:50:08+08:00">2024-09-29</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-10-05 17:46:52" itemprop="dateModified" datetime="2024-10-05T17:46:52+08:00">2024-10-05</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/research/" itemprop="url" rel="index"><span itemprop="name">research</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="1-研究的问题"><a href="#1-研究的问题" class="headerlink" title="1. 研究的问题"></a>1. 研究的问题</h3><p>这篇论文探讨的核心问题是设计一种收益最大化的激励相容机制，用于在线零售环境中的联合广告销售。具体来说，就是如何将一个广告位（例如）出售给两个不可排除的买家（例如，一个商家和一个品牌），这两个买家可能共同在拍卖中出价以推广一个产品，并且都从广告的展示中获益。该问题涉及到设计一个机制，该机制从两个买家那里收集出价，并决定是否分配广告位以及两个参与方应支付的金额。这个问题引出了复杂的激励相容性约束，例如，如何在两个参与方之间分配付款。</p>
<h3 id="2-研究的对象"><a href="#2-研究的对象" class="headerlink" title="2. 研究的对象"></a>2. 研究的对象</h3><p>研究对象是在线零售领域的广告销售机制，尤其是在涉及两个或多个买家共同对一个非排他性商品（如广告位）出价的场景。论文特别关注了那些在拍卖设计中产生的复杂问题，包括如何在不同的买家之间分割付款，以及如何确保拍卖机制既能最大化收益，又能满足激励相容性和个体理性的要求。</p>
<h3 id="3-使用的技术"><a href="#3-使用的技术" class="headerlink" title="3. 使用的技术"></a>3. 使用的技术</h3><p>论文采用了在线学习视角来解决寻找收益最大化激励相容机制的问题。作者提出了一种高效的学习算法，该算法基于自适应离散化机制空间的方法，因为任何非自适应离散化都无法实现次线性遗憾。在随机设置中（即代理的估值根据某些固定但未知的分布进行抽取），作者设计了一个有效的学习算法，实现了 (\tilde{O}(n^{3&#x2F;4})) 的遗憾界限。而在对抗性设置中（即估值是预先任意生成的），作者利用问题的非Lipschitz性质来证明一个强有力的负面结果，即没有任何学习算法能够实现超过最佳固定机制收益的一半。</p>
<p>此外，论文还考虑了 (\pi)-平滑对手设置，即估值随机生成自平滑分布，但与随机情况不同，可以以非平稳方式进行。在这个设置中，作者构建了一个有效的学习算法，实现了 (\tilde{O}(n^{2&#x2F;3})) 的遗憾界限，并基于对数数量级的专家进行简洁编码。最后，作者证明了在随机和平滑设置中，没有任何学习算法能够实现小于 (\Omega(\sqrt{n})) 的遗憾，从而缩小了这两种问题中最小最大遗憾率的范围。</p>
<h3 id="1-Research-Problem"><a href="#1-Research-Problem" class="headerlink" title="1. Research Problem"></a>1. Research Problem</h3><p>The core issue explored in this paper is the design of a revenue-maximizing incentive-compatible mechanism for selling a non-excludable good, such as an advertisement slot, to two cooperative bidders (e.g., a merchant and a brand). This problem captures scenarios where two parties jointly bid in an auction and both benefit from the ad being displayed. The mechanism collects bids from both parties and decides on the allocation and payments. This gives rise to intricate incentive compatibility constraints, such as how to split payments between the two parties. The paper tackles the problem of finding a revenue-maximizing incentive-compatible mechanism from an online learning perspective, which poses significant technical challenges due to the large action space and the highly irregular function mapping mechanisms to revenue.</p>
<h3 id="2-Research-Object"><a href="#2-Research-Object" class="headerlink" title="2. Research Object"></a>2. Research Object</h3><p>The research object is the mechanism design for selling joint advertisements in the online retail sector, specifically focusing on scenarios where multiple bidders are involved in the bidding process for a single, non-excludable item. The paper is particularly concerned with the complexities that arise in auction design, including how to divide payments among different bidders and ensuring that the auction mechanism maximizes revenue while meeting the criteria for incentive compatibility and individual rationality.</p>
<h3 id="3-Used-Technology"><a href="#3-Used-Technology" class="headerlink" title="3. Used Technology"></a>3. Used Technology</h3><p>The paper employs an online learning approach to address the challenge of identifying a revenue-maximizing incentive-compatible mechanism. The authors propose an efficient learning algorithm based on an adaptive discretization scheme of the mechanism space, as any non-adaptive discretization fails to achieve sublinear regret. In the stochastic setting, where agents’ valuations are drawn from a fixed but unknown distribution, the algorithm achieves a regret bound of (\tilde{O}(n^{3&#x2F;4})). In the adversarial setting, where valuations are arbitrarily generated upfront, the authors exploit the non-Lipschitzness of the problem to prove a strong negative result, indicating that no learning algorithm can achieve more than half of the revenue of the best fixed mechanism in hindsight. They also consider the (\pi)-smooth adversary setting, where valuations are randomly generated from smooth distributions but can be non-stationary. In this setting, they construct an efficient learning algorithm that achieves a regret bound of (\tilde{O}(n^{2&#x2F;3})) and is based on a succinct encoding of exponentially many experts. Finally, they prove that no learning algorithm can achieve less than (\Omega(\sqrt{n})) regret in both the stochastic and the smooth setting, thus narrowing the range where the minimax regret rates for these two problems lie.</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" title="下一页" aria-label="下一页" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Yuhan Wang</span>
  </div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>





  <script src="/js/third-party/pace.js"></script>


  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
